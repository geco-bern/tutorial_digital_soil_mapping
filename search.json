[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AGDS 2: Digital Soil Mapping",
    "section": "",
    "text": "Preface\nThis online book covers the tutorial on digital soil mapping from the course Applied Geodata Science 2 at the University of Bern. Material is adapted from work by Madlene Nussbaum.\n\n\nSystem Setup\nIf you want to replicate the code of this tutorial, we suggest to either load the latest renv.lock file from this tutorial’s repository and load it using the {renv} package. Alternatively, the output below could be used to traceback and install the exact package versions that were used in this tutorial.\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.4.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] compiler_4.3.1  fastmap_1.1.1   cli_3.6.1       tools_4.3.1    \n [5] htmltools_0.5.5 rstudioapi_0.14 rmarkdown_2.22  knitr_1.43     \n [9] jsonlite_1.8.5  xfun_0.39       digest_0.6.31   rlang_1.1.1    \n[13] evaluate_0.21"
  },
  {
    "objectID": "01-introduction.html#spatial-data-science-an-introduction",
    "href": "01-introduction.html#spatial-data-science-an-introduction",
    "title": "1  Introduction",
    "section": "1.1 Spatial Data Science: An Introduction",
    "text": "1.1 Spatial Data Science: An Introduction\nSpatial data science combines geography, statistics, computer science, and data science to analyze and interpret spatially referenced data. It focuses on uncovering patterns and relationships in geospatial data to gain insights into spatial phenomena. By integrating locational information, spatial data science provides a deeper understanding of complex spatial patterns and processes. There are three key aspects of spatial data science that allow such a deeper understanding:\n\nSpatial Data Visualization: Visualizing spatial data through maps and interactive visualizations helps communicate complex spatial information effectively.\nSpatial Data Analysis: Techniques such as spatial clustering, spatial autocorrelation analysis, and spatial regression reveal spatial patterns, trends, and dependencies.\nGeospatial Machine Learning: Applying machine learning algorithms to spatial data enables the creation of predictive models for spatially explicit predictions.\n\nCombined, working on each of these aspects, allows for a variety of real-world applications, for example, in urban planning, ecology, transportation, public health, or social sciences. The knowledge create through maps, analysis, and prediction reveals fundamental processes to understand spatial relationships, and to eventually improve decision-making."
  },
  {
    "objectID": "01-introduction.html#spatial-upscaling-with-machine-learning-methods",
    "href": "01-introduction.html#spatial-upscaling-with-machine-learning-methods",
    "title": "1  Introduction",
    "section": "1.2 Spatial Upscaling with Machine Learning Methods",
    "text": "1.2 Spatial Upscaling with Machine Learning Methods\nSpatial upscaling describes the process of extrapolating information from a smaller to a larger area. Spatial upscaling is used to solve the common problem where we have a variable of interest measured at a few sampling locations, whilst having large maps of potential covariates that could predict that variable. As discussed further below, this a variable of interest could be a soil characteristic that has to be sampled by digging up soil and analyzing it in the lab. Potential covariates are often remote-sensing data or pre-existing maps of e.g., geological features. Recent technological progress substantially facilitated the acquisition of remote-sensing data and in combination with increased computational capacity, we can use a variety of machine learning tools to investigate our variable of interest at larger scales.\nAlthough the field of spatial data science or geostatistics has gained great interest in recent years, our fundamental understanding rests on hundreds of years on decades of research. For example, quoting Waldo Tobler, a famous American-Swiss geographer, the first law of geography is that “everything is related to everything else, but near things are more related than distant things” (Tobler, 1970). This is the essential idea of spatial autocorrelation, an inherent feature of spatial data that can influence the validity of statistical analyses and spatial modelling and that therefore must be accounted for in any spatial analysis. Due to their simplistic interpretability and applicability, up-scaled maps are increasingly popular in the scientific literature but remember that publishing such maps should always come with stringent evaluation (Meyer & Pebesma, 2021, 2022)."
  },
  {
    "objectID": "01-introduction.html#case-study-digital-soil-mapping-with-random-forests",
    "href": "01-introduction.html#case-study-digital-soil-mapping-with-random-forests",
    "title": "1  Introduction",
    "section": "1.3 Case-Study: Digital Soil Mapping with Random Forests",
    "text": "1.3 Case-Study: Digital Soil Mapping with Random Forests\nIn this tutorial, we are look at a specific case of spatial upscaling: digital soil mapping using Random Forests. This means, we want to predict soil properties that are difficult to obtain from more abundant data. Good data science always require domain knowledge. Thus, it is important that you have basic knowledge on soil science. Generally, any soil is the result of five key pedogenetic factors (Jenny, 1994). Abbreviated, they can be simply memorized with the mnemonic “CLOPRT”: soil = f(climate, organisms, topography, parent material, time, … ). The “…” stands for additional factors that may not fall under the CLORPT scheme. soil itself can stand for a variety of soil properties like its texture, density, pH, water drainage, organic matter content, etc. Note that especially information on climate, topography, and parent material (think of geological maps) are highly abundant nowadays, which makes them great predictor variables in machine learning methods.\nAlso note that the variety in pedogenetic factors and soil properties comes with an equal variety of data types with variables that can be numerical (capped like % of clay content, or un-capped like organic matter content), binary (e.g., presence of water at 0-10cm soil depth), categorical (more than two without an order), ordinal (more than two with an order), or interval (cutting numerical values into intervals). Moreover, this data can come in different formats such as tables or rasters. Due to this abundance of data types and their peculiarities, it is of great importance to properly understand your data. Only when you know your data well, you can pick a suitable statistical model to address your research question. To create reliable prediction using this data variety, our statistical model should…\n\n… capture non-linear relations, because pedogenesis is a non-linear process.\n… be able to use and predict continuous and categorical variables.\n… handle multiple correlated variables without the risk of overfitting.\n… account for spatial auto-correlation (this is a bit tricky, so more on this in Chapter 2).\n… build models with good predictive power.\n… result in a sparse model, keeping only relevant predictors.\n… quantify prediction accuracy and uncertainty.\n\nIn this tutorial, we use a dataset on basic soil properties from sampling locations across the canton of Bern and pair it up with climatic variables (temperature, precipitation, radiation), terrain attributes (derivatives from digital elevation models like slope, northness, eastness, topographic water index, etc.), geological maps, and soil maps (Nussbaum et al., 2017). The following chapters will cover the preparation of this data (Chapter 2), fitting a Random Forest model (Chapter 3), and evaluating this model (Chapter 4). The final Chapter 5 holds the exercise description of this tutorial.\nIf you want to learn more about the underlying theory and similar techniques, we highly recommend the presentations by Madlene Nussbaum given at the summer school of the OpenGeoHub Foundation (see part 1 and 2).\n\n\n\n\nJenny, H. (1994). Factors of soil formation: A system of quantitative pedology. Dover.\n\n\nMeyer, H., & Pebesma, E. (2021). Predicting into unknown space? Estimating the area of applicability of spatial prediction models. Methods in Ecology and Evolution, 2041–210X.13650. https://doi.org/10.1111/2041-210X.13650\n\n\nMeyer, H., & Pebesma, E. (2022). Machine learning-based global maps of ecological variables and the challenge of assessing them. Nature Communications, 13(1), 2208. https://doi.org/10.1038/s41467-022-29838-9\n\n\nNussbaum, M., Walthert, L., Fraefel, M., Greiner, L., & Papritz, A. (2017). Mapping of soil properties at high resolution in Switzerland using boosted geoadditive models. SOIL, 3(4), 191–210. https://doi.org/10.5194/soil-3-191-2017\n\n\nTobler, W. R. (1970). A computer movie simulating urban growth in the detroit region. Economic Geography, 46, 234–240. https://doi.org/10.2307/143141"
  },
  {
    "objectID": "02-data_preparation.html#load-data",
    "href": "02-data_preparation.html#load-data",
    "title": "2  Preparing Raster Data",
    "section": "2.1 Load data",
    "text": "2.1 Load data\n\n2.1.1 Sampling location data\n\n\nCode\n# Load soil data from sampling locations\nbern_data &lt;- readr::read_csv(\n  here::here(\"data-raw/soildata/berne_soil_sampling_locations.csv\")\n  )\n\n# Display data\nhead(bern_data) |&gt; knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsite_id_unique\ntimeset\nx\ny\ndataset\ndclass\nwaterlog.30\nwaterlog.50\nwaterlog.100\nph.0.10\nph.10.30\nph.30.50\nph.50.100\n\n\n\n\n4_26-In-005\nd1968_1974_ptf\n2571994\n1203001\nvalidation\npoor\n0\n0\n1\n6.071733\n6.227780\n7.109235\n7.214589\n\n\n4_26-In-006\nd1974_1978\n2572149\n1202965\ncalibration\npoor\n0\n1\n1\n6.900000\n6.947128\n7.203502\n7.700000\n\n\n4_26-In-012\nd1974_1978\n2572937\n1203693\ncalibration\nmoderate\n0\n1\n1\n6.200000\n6.147128\n5.603502\n5.904355\n\n\n4_26-In-014\nd1974_1978\n2573374\n1203710\nvalidation\nwell\n0\n0\n0\n6.600000\n6.754607\n7.200000\n7.151129\n\n\n4_26-In-015\nd1968_1974_ptf\n2573553\n1203935\nvalidation\nmoderate\n0\n0\n1\n6.272715\n6.272715\n6.718392\n7.269008\n\n\n4_26-In-016\nd1968_1974_ptf\n2573310\n1204328\ncalibration\npoor\n0\n0\n1\n6.272715\n6.160700\n5.559031\n5.161655\n\n\n\n\n\nThe dataset on soil samples from Bern holds 13 variables for 1052 entries (more information here):\n\nsite_id_unique: The location’s unique site id.\ntimeset: The sampling year and information on sampling type for soil pH (no label: CaCl\\(_2\\) laboratory measurement, field: indicator solution used in field, ptf: H\\(_2\\)O laboratory measurement transferred by pedotransfer function).\nx: The x (easting) coordinates in meters following the (CH1903/LV03) system.\ny: The y (northing) coordinates in meters following the (CH1903/LV03) system.\ndataset: Specification whether a sample is used for model calibration or validation (this is based on randomization to ensure even spatial coverage).\ndclass: Soil drainage class\nwaterlog.30, waterlog.50, waterlog.100: Specification whether soil was water logged at 30, 50, or 100 cm depth (0 = No, 1 = Yes).\nph.0.10, ph.10.30, ph.30.50, ph.50.100: Average soil pH between 0-10, 10-30, 30-50, and 50-100 cm depth.\n\n\n\n2.1.2 Raster data of covariates\nNow, let’s load all the covariates that we want to produce our soil maps.\n\n\nCode\n# Get a list with the path to all raster files\nlist_raster &lt;- \n  base::list.files(\n    here::here(\"data-raw/geodata/covariates/\"),\n    full.names = T\n  )\n\n# Display data (lapply to clean names)\nlapply(\n  list_raster, \n  function(x) sub(\".*/(.*)\", \"\\\\1\", x)\n  ) |&gt; \n  unlist() |&gt; \n  head(5) |&gt; \n  print()\n\n\n[1] \"be_gwn25_hdist.tif\" \"be_gwn25_vdist.tif\" \"cindx10_25.tif\"    \n[4] \"cindx50_25.tif\"     \"geo500h1id.tif\"    \n\n\nThe output above shows the first five raster files with rather cryptic names. For this tutorial, we do not need to know all of the 91 rasters files that we are loading here but in a scientific context, you should know your data better of course. Let’s look at one of these raster files to get a better feeling for our data:\n\n\nCode\n# Load a raster file as example: Picking the slope profile at 2m resolution\nraster_example &lt;- terra::rast(list_raster[74])\nraster_example\n\n\nclass       : SpatRaster \ndimensions  : 986, 2428, 1  (nrow, ncol, nlyr)\nresolution  : 20, 20  (x, y)\nextent      : 2568140, 2616700, 1200740, 1220460  (xmin, xmax, ymin, ymax)\ncoord. ref. : CH1903+ / LV95 \nsource      : Se_slope2m.tif \nname        : Se_slope2m \nmin value   :    0.00000 \nmax value   :   85.11286 \n\n\nAs shown in the output, a raster object has the following properties (among others, see ?terra::rast):\n\nclass: The class of the file, here a SpatRaster.\ndimensions: The number of rows, columns, years (if temporal encoding).\nresolution: The resolution of the coordinate system, here it is 20 in both axes.\nextent: The extent of the coordinate system defined by min and max values on the x and y axes.\ncoord. ref.: Reference coordinate system. Here, the raster is encoded using the LV95 geodetic reference system from which the projected coordinate system CH1903+ is derived.\nsource: The name of the source file.\nnames: The name of the raster file (mostly the file name without file-specific ending)\nmin value: The lowest value of all cells.\nmax value: The highest value of all cells.\n\nNow, let’s look at a visualisation of this raster file. Since we selected the slope at 2m resolution, we expect a relief-like map with a color gradient that indicates the steepness of the terrain.\n\n\nCode\n# Plot raster example\nterra::plot(raster_example)\n\n\n\n\n\n\n\nCode\n# To have some more flexibility, we can plot this in the ggplot-style as such:\nggplot2::ggplot() +\n  tidyterra::geom_spatraster(data = raster_example) +\n  ggplot2::scale_fill_viridis_c(\n    na.value = NA,\n    option = \"magma\",\n    name = \"Slope (%) \\n\"\n    ) +\n  ggplot2::theme_bw() +\n  ggplot2::scale_x_continuous(expand = c(0, 0)) +  # avoid gap between plotting area and axis\n  ggplot2::scale_y_continuous(expand = c(0, 0)) +\n  ggplot2::labs(title = \"Slope of the Study Area\")\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the second plot has different coordinates than the upper one. That is because the data was automatically projected to the World Geodetic System (WGS84, ESPG: 4326).\n\n\nThis looks already interesting but we can put our data into a bit more context. For example, a larger map background would be useful to get a better orientation of our location. Also, it would be nice to see where our sampling locations are and to differentiate these locations by whether they are part of the calibration or validation dataset. Bringing this all together requires some more understanding of plotting maps in R. So, don’t worry if you do not understand everything in the code chunk below and enjoy the visualisations:\n\n\n\nCode\n# To get our map working correctly, we have to ensure that all the input data\n# is in the same coordinate system. Since our Berne data is in the Swiss \n# coordinate system, we have to transform the sampling locations to the \n# World Geodetic System first.\n\n# For the raster:\nr &lt;- terra::project(raster_example, \"+init=EPSG:4326\")\n\n# For the sampling locations:\n# Function from Stackoverflow:\n# https://stackoverflow.com/questions/49536664/r-transforming-coordinates-inside-the-data-frame\nchange_coords &lt;-function(data, from_CRS, to_CRS) {\n  \n  # Load required package\n  require(sp)\n  \n  # Turn string into CRS\n  from_CRS = CRS(from_CRS)\n  to_CRS   = CRS(to_CRS)\n  \n  new &lt;- \n    as.data.frame(\n      spTransform(\n        SpatialPointsDataFrame(\n          coords = data.frame(\n            lon = data$lon,\n            lat = data$lat),\n          \n          data = data.frame(\n            id = data$id,\n            lon_old = data$lon,\n            lat_old = data$lat),\n          proj4string = from_CRS), \n        to_CRS\n        )\n      )\n  \n  new &lt;- \n    new |&gt; \n    dplyr::select(coords.x1, coords.x2, id) |&gt; \n    dplyr::rename(lon = coords.x1,\n                  lat = coords.x2)\n  \n  return(new)\n}\n\n# Transform dataframes\ncoord_cal &lt;- \n  bern_data |&gt; \n  dplyr::filter(dataset == \"calibration\") |&gt; \n  dplyr::select(site_id_unique, x, y) |&gt; \n  dplyr::rename(id = site_id_unique, lon = x, lat = y) |&gt; \n  change_coords(\n    from_CRS = \"+init=epsg:2056\", \n    to_CRS = \"+init=epsg:4326\"\n    )\n\ncoord_val &lt;- \n  bern_data |&gt; \n  dplyr::filter(dataset == \"validation\") |&gt; \n  dplyr::select(site_id_unique, x, y) |&gt; \n  dplyr::rename(id = site_id_unique, lon = x, lat = y) |&gt; \n  change_coords(\n    from_CRS = \"+init=epsg:2056\", \n    to_CRS = \"+init=epsg:4326\"\n    )\n\n\n\n\nCode\n# Loading packages to improve code readbility to avoid :: notation\n# Note: This code may only work when installing the development branch of {leaflet}:\n# remotes::install_github('rstudio/leaflet')\nlibrary(leaflet)\nlibrary(terra)\n\n# Let's get a nice color palette now for easy reference\npal &lt;- colorNumeric(\n  \"magma\",\n  values(r),\n  na.color = \"transparent\"\n  )\n\n# Next, we build a leaflet map\nleaflet() |&gt; \n  # As base maps, use two provided by ESRI\n  addProviderTiles(providers$Esri.WorldImagery, group = \"World Imagery\") |&gt;\n  addProviderTiles(providers$Esri.WorldTopoMap, group = \"World Topo\") |&gt;\n  # Add our raster file\n  addRasterImage(\n    r,\n    colors = pal,\n    opacity = 0.6,\n    group = \"raster\"\n    ) |&gt;\n  # Add markers for sampling locations\n  leaflet::addCircleMarkers(\n    data = coord_cal,\n    lng = ~lon,  # Column name for x coordinates\n    lat = ~lat,  # Column name for y coordinates\n    group = \"training\",\n    color = \"black\"\n  ) |&gt;\n    leaflet::addCircleMarkers(\n    data = coord_val,\n    lng = ~lon,  # Column name for x coordinates\n    lat = ~lat,  # Column name for y coordinates\n    group = \"validation\",\n    color = \"red\"\n  ) |&gt;\n  # Add some layout and legend\n  addLayersControl(\n    baseGroups = c(\"World Imagery\",\"World Topo\"),\n    position = \"topleft\",\n    options = layersControlOptions(collapsed = FALSE),\n    overlayGroups = c(\"raster\", \"training\", \"validation\")\n    ) |&gt;\n  addLegend(\n    pal = pal,\n    values = values(r),\n    title = \"Slope (%)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis plotting example is based to the one shown in the AGDS 2 tutorial “Handful of Pixels” on phenology and more information on using spatial data in R can be found in the Chapter on Geospatial data in R.\n\n\nThat looks great! At first glance, it is a bit crowded but once you scroll in you can investigate our study area quite nicely. You can check whether the slope raster file makes sense by comparing it against the base maps. Can you see how cliffs along the Aare river, hills, and even gravel quarries show high slopes? We also see that our validation dataset is nicely distributed across the area covered by the training dataset.\nNow that we have played with a few visualizations, let’s get back to preparing our data. The {terra} package comes with the very useful tool to stack multiple raster on top of each other, if they are of the same spatial format. To do so, we just have to feed in the vector of file names list_raster:\n\n\nCode\n# Load all files as one batch\nall_rasters &lt;- terra::rast(list_raster)\nall_rasters\n\n\nclass       : SpatRaster \ndimensions  : 986, 2428, 91  (nrow, ncol, nlyr)\nresolution  : 20, 20  (x, y)\nextent      : 2568140, 2616700, 1200740, 1220460  (xmin, xmax, ymin, ymax)\ncoord. ref. : CH1903+ / LV95 \nsources     : be_gwn25_hdist.tif  \n              be_gwn25_vdist.tif  \n              cindx10_25.tif  \n              ... and 88 more source(s)\nnames       :  be_gw~hdist, be_gw~vdist, cindx10_25, cindx50_25, geo500h1id, geo500h3id, ... \nmin values  :    0.4998779,       0.000,       -100,  -99.99999,          1,          0, ... \nmax values  : 3181.2531475,    1165.709,        100,   57.94390,         99,         56, ... \n\n\nNow, we do not want to have the covariates’ data from all cells in the raster file. Rather, we want to reduce our stacked rasters to the x and y coordinates for which we have soil sampling data. We can do this using the terra::extract() function. Then, we want to merge the two dataframes of soil data and covariates data by their coordinates. Since the order of the covariate data is the same as the Bern data, we can simply bind their columns with cbind():\n\n\nCode\n# Extract coordinates from sampling locations\nsampling_xy &lt;- bern_data |&gt; dplyr::select(x, y)\n\n# From all rasters, extract values for sampling coordinates\ncovar_data &lt;- \n  terra::extract(all_rasters,  # The raster we want to extract from\n                 sampling_xy,  # A matrix of x and y values to extract for\n                 ID = FALSE    # To not add a default ID column to the output\n                 )\n\nmerged_data &lt;- cbind(bern_data, covar_data)\nhead(merged_data) |&gt; knitr::kable() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsite_id_unique\ntimeset\nx\ny\ndataset\ndclass\nwaterlog.30\nwaterlog.50\nwaterlog.100\nph.0.10\nph.10.30\nph.30.50\nph.50.100\nbe_gwn25_hdist\nbe_gwn25_vdist\ncindx10_25\ncindx50_25\ngeo500h1id\ngeo500h3id\nlgm\nlsf\nmrrtf25\nmrvbf25\nmt_gh_y\nmt_rr_y\nmt_td_y\nmt_tt_y\nmt_ttvar\nNegO\nPosO\nprotindx\nSe_alti2m_std_50c\nSe_conv2m\nSe_curv25m\nSe_curv2m_fmean_50c\nSe_curv2m_fmean_5c\nSe_curv2m_s60\nSe_curv2m_std_50c\nSe_curv2m_std_5c\nSe_curv2m\nSe_curv50m\nSe_curv6m\nSe_curvplan25m\nSe_curvplan2m_fmean_50c\nSe_curvplan2m_fmean_5c\nSe_curvplan2m_s60\nSe_curvplan2m_s7\nSe_curvplan2m_std_50c\nSe_curvplan2m_std_5c\nSe_curvplan2m\nSe_curvplan50m\nSe_curvprof25m\nSe_curvprof2m_fmean_50c\nSe_curvprof2m_fmean_5c\nSe_curvprof2m_s60\nSe_curvprof2m_s7\nSe_curvprof2m_std_50c\nSe_curvprof2m_std_5c\nSe_curvprof2m\nSe_curvprof50m\nSe_diss2m_50c\nSe_diss2m_5c\nSe_e_aspect25m\nSe_e_aspect2m_5c\nSe_e_aspect2m\nSe_e_aspect50m\nSe_MRRTF2m\nSe_MRVBF2m\nSe_n_aspect2m_50c\nSe_n_aspect2m_5c\nSe_n_aspect2m\nSe_n_aspect50m\nSe_n_aspect6m\nSe_NO2m_r500\nSe_PO2m_r500\nSe_rough2m_10c\nSe_rough2m_5c\nSe_rough2m_rect3c\nSe_SAR2m\nSe_SCA2m\nSe_slope2m_fmean_50c\nSe_slope2m_fmean_5c\nSe_slope2m_s60\nSe_slope2m_s7\nSe_slope2m_std_50c\nSe_slope2m_std_5c\nSe_slope2m\nSe_slope50m\nSe_slope6m\nSe_toposcale2m_r3_r50_i10s\nSe_tpi_2m_50c\nSe_tpi_2m_5c\nSe_tri2m_altern_3c\nSe_tsc10_2m\nSe_TWI2m_s15\nSe_TWI2m_s60\nSe_TWI2m\nSe_vrm2m_r10c\nSe_vrm2m\nterrTextur\ntsc25_18\ntsc25_40\nvdcn25\nvszone\n\n\n\n\n4_26-In-005\nd1968_1974_ptf\n2571994\n1203001\nvalidation\npoor\n0\n0\n1\n6.071733\n6.227780\n7.109235\n7.214589\n234.39087\n1.2986320\n-10.62191\n-6.9658718\n6\n0\n7\n0.0770846\n0.0184651\n4.977099\n1316.922\n9931.120\n58\n98\n183\n1.569110\n1.534734\n0.0159717\n0.3480562\n-40.5395088\n-0.0014441\n-0.0062570\n0.0175912\n0.0002296\n2.9204133\n1.1769447\n-1.9364884\n0.0031319\n-0.5886537\n-0.0042508\n-0.0445323\n-0.0481024\n-0.0504083\n-0.1655090\n1.5687343\n0.6229440\n-1.0857303\n0.0007920\n-0.0028067\n-0.0382753\n-0.0656936\n-0.0506380\n-0.0732220\n1.6507173\n0.7082230\n0.8507581\n-0.0023399\n0.3934371\n0.1770810\n-0.9702092\n-0.7929600\n-0.5661940\n-0.9939429\n5.930607\n6.950892\n-0.2840056\n-0.6084610\n-0.2402939\n-0.0577110\n-0.7661251\n1.562085\n1.548762\n0.3228087\n0.2241062\n0.2003846\n4.000910\n16.248077\n0.9428899\n0.6683306\n0.9333237\n0.7310556\n0.8815832\n0.3113754\n1.1250136\n0.3783818\n0.5250366\n0\n-0.0940372\n-0.0583917\n10.319408\n0.4645128\n0.0032796\n0.0049392\n0.0011592\n0.000125\n0.0002450\n0.6248673\n0.3332805\n1.784737\n65.62196\n6\n\n\n4_26-In-006\nd1974_1978\n2572149\n1202965\ncalibration\npoor\n0\n1\n1\n6.900000\n6.947128\n7.203502\n7.700000\n127.41681\n1.7064546\n-10.87862\n-11.8201790\n6\n0\n7\n0.0860347\n0.0544361\n4.975796\n1317.000\n9931.672\n58\n98\n183\n1.568917\n1.533827\n0.0204794\n0.1484705\n19.0945148\n-0.0190294\n0.0021045\n0.0221433\n0.0000390\n3.8783867\n4.3162045\n2.1377332\n-0.0171786\n0.1278165\n-0.0119618\n-0.0501855\n-0.3270764\n-0.1004921\n-0.5133076\n2.0736780\n2.2502327\n-0.3522736\n-0.0073879\n0.0070676\n-0.0522900\n-0.3492197\n-0.1005311\n-0.4981292\n2.1899190\n2.4300070\n-2.4900069\n0.0097907\n0.4014700\n0.7360508\n0.5683194\n0.8753148\n-0.3505180\n0.3406741\n5.984921\n6.984581\n-0.5732749\n0.4801802\n0.4917848\n-0.4550385\n0.7722272\n1.543384\n1.558683\n0.2730940\n0.2489859\n0.2376962\n4.001326\n3.357315\n1.0895698\n0.9857153\n1.0231543\n1.0398037\n1.0152543\n0.5357812\n1.3587183\n0.0645478\n0.5793087\n0\n-0.0014692\n0.0180000\n12.603136\n0.5536283\n0.0070509\n0.0067992\n0.0139006\n0.000300\n0.0005389\n0.7573612\n0.3395441\n1.832904\n69.16074\n6\n\n\n4_26-In-012\nd1974_1978\n2572937\n1203693\ncalibration\nmoderate\n0\n1\n1\n6.200000\n6.147128\n5.603502\n5.904355\n143.41533\n0.9372618\n22.10210\n0.2093917\n6\n0\n7\n0.0737963\n3.6830916\n4.986864\n1315.134\n9935.438\n58\n98\n183\n1.569093\n1.543057\n0.0048880\n0.1112066\n-9.1396294\n0.0039732\n0.0009509\n0.0431735\n0.0034232\n0.7022317\n0.4170935\n-0.4178924\n-0.0026431\n-0.0183221\n0.0015183\n-0.0079620\n0.0053904\n-0.0091239\n-0.0110896\n0.3974485\n0.2292406\n-0.2168447\n-0.0013561\n-0.0024548\n-0.0089129\n-0.0377831\n-0.0125471\n-0.0052359\n0.4158890\n0.2700820\n0.2010477\n0.0012870\n0.6717541\n0.4404107\n-0.6987815\n-0.3866692\n-0.1960597\n-0.7592779\n5.953919\n6.990917\n-0.3006475\n-0.9221049\n-0.9633239\n-0.3257418\n-0.9502072\n1.565405\n1.563151\n0.2305476\n0.2182523\n0.1434273\n4.000320\n11.330072\n0.5758902\n0.5300468\n0.5107915\n0.5744110\n0.4975456\n0.2001768\n0.7160403\n0.1311051\n0.4620202\n0\n0.0340407\n-0.0145804\n7.100000\n0.4850160\n0.0021498\n0.0017847\n0.0011398\n0.000000\n0.0000124\n0.7978453\n0.4455501\n1.981526\n63.57096\n6\n\n\n4_26-In-014\nd1974_1978\n2573374\n1203710\nvalidation\nwell\n0\n0\n0\n6.600000\n6.754607\n7.200000\n7.151129\n165.80418\n0.7653937\n-20.11569\n-7.7729993\n6\n0\n7\n0.0859686\n0.0075817\n5.285522\n1315.160\n9939.923\n58\n98\n183\n1.569213\n1.542792\n0.0064054\n0.3710849\n-0.9318936\n-0.0371234\n0.0029348\n-0.1056513\n0.0127788\n1.5150748\n0.2413423\n-0.0289909\n0.0020990\n-0.0706228\n-0.0113604\n-0.0301961\n-0.0346193\n-0.0273140\n-0.0343277\n0.8245047\n0.1029889\n-0.0272214\n-0.0041158\n0.0257630\n-0.0331309\n0.0710320\n-0.0400928\n0.0529446\n0.8635767\n0.1616543\n0.0017695\n-0.0062147\n0.4988544\n0.4217250\n-0.8485889\n-0.8657616\n-0.8836724\n-0.8993938\n4.856076\n6.964162\n-0.5735765\n-0.4998477\n-0.4677161\n-0.4121092\n-0.4782534\n1.562499\n1.562670\n0.3859352\n0.2732429\n0.1554769\n4.000438\n42.167496\n0.8873205\n0.8635756\n0.9015982\n0.8518201\n0.5767300\n0.2149791\n0.8482135\n0.3928713\n0.8432562\n0\n0.0686932\n-0.0085602\n8.303085\n0.3951114\n0.0008454\n0.0021042\n0.0000000\n0.000100\n0.0000857\n0.4829135\n0.4483251\n2.113142\n64.60535\n6\n\n\n4_26-In-015\nd1968_1974_ptf\n2573553\n1203935\nvalidation\nmoderate\n0\n0\n1\n6.272715\n6.272715\n6.718392\n7.269008\n61.39244\n1.0676192\n-55.12566\n-14.0670462\n6\n0\n7\n0.0650000\n0.0007469\n5.894688\n1315.056\n9942.032\n58\n98\n183\n1.570359\n1.541979\n0.0042235\n0.3907509\n4.2692256\n0.0378648\n0.0022611\n-0.1020419\n0.0161510\n3.6032522\n1.8169731\n0.6409346\n0.0346340\n0.0476020\n0.0378154\n-0.0179657\n-0.0137853\n-0.0146946\n0.0060875\n1.4667766\n0.9816071\n0.2968794\n0.0337645\n-0.0000494\n-0.0202268\n0.0882566\n-0.0308456\n0.0929077\n2.6904552\n1.0218329\n-0.3440553\n-0.0008695\n0.6999696\n0.3944107\n-0.8918364\n-0.8864348\n-0.7795515\n-0.4249992\n4.130917\n6.945287\n0.4304937\n0.4614536\n0.5919228\n0.6559467\n0.4574654\n1.550528\n1.562685\n0.4330348\n0.3299487\n0.1889674\n4.000948\n5.479310\n1.8937486\n1.2098556\n1.5986075\n1.2745584\n2.7759163\n0.5375320\n1.2301254\n0.3582314\n1.1426100\n0\n0.3005829\n0.0061576\n10.110727\n0.5134069\n0.0043268\n0.0045225\n0.0054557\n0.000200\n0.0002062\n0.6290755\n0.3974232\n2.080674\n61.16533\n6\n\n\n4_26-In-016\nd1968_1974_ptf\n2573310\n1204328\ncalibration\npoor\n0\n0\n1\n6.272715\n6.160700\n5.559031\n5.161655\n310.05014\n0.1321367\n-17.16055\n-28.0693741\n6\n0\n7\n0.0731646\n0.0128017\n5.938320\n1315.000\n9940.597\n58\n98\n183\n1.569434\n1.541606\n0.0040683\n0.1931891\n-0.1732794\n-0.1602274\n-0.0035833\n-0.1282881\n0.0003549\n1.5897882\n0.8171870\n0.0318570\n-0.0123340\n0.0400775\n-0.0813964\n-0.0049875\n0.0320331\n-0.0049053\n0.0374298\n0.7912259\n0.3455668\n0.0100844\n-0.0059622\n0.0788309\n-0.0014042\n0.1603212\n-0.0052602\n0.0867119\n1.0207798\n0.6147888\n-0.0217726\n0.0063718\n0.3157751\n0.5292308\n-0.8766075\n0.5905659\n0.8129975\n0.1640853\n2.030315\n6.990967\n0.6325440\n0.8054439\n0.5820994\n0.7448481\n0.6081498\n1.563066\n1.552568\n0.3688371\n0.2607146\n0.1763995\n4.000725\n13.499996\n1.0418727\n0.8515157\n1.2106605\n0.8916541\n1.2163279\n0.4894866\n1.0906221\n0.2049688\n0.7156029\n0\n-0.0910767\n0.0034276\n9.574804\n0.3864355\n0.0001476\n0.0003817\n0.0000000\n0.000525\n0.0001151\n0.6997021\n0.4278295\n2.041467\n55.78354\n6\n\n\n\n\n\n\nGreat that worked without problems. Now, to allow spatial trend in more directions than only in a north-south and east-west direction, we have to add polar coordinates:\n\n\nCode\nfinal_data &lt;- \n  merged_data |&gt; \n    dplyr::mutate(\n      x30 = x*cos(30/180*pi) - y*sin(30/180*pi),\n      y30 = x*sin(30/180*pi) + y*cos(30/180*pi),\n      x60 = x*cos(60/180*pi) - y*sin(60/180*pi),\n      y60 = x*sin(60/180*pi) + y*cos(60/180*pi)\n    )\n\n\nNot all our covariates may be continuous variables and therefore have should be encoded as factors. As an easy check, we can take the original corvariates data and check for the number of unique values in each raster. If the variable is continuous, we expect that there are a lot of different values - at maximum 1052 different values because we have that many entries. So, let’s have a look and assume that variables with 10 or less different values are categorical variables.\n\n\nCode\ncat_vars &lt;- \n  covar_data |&gt; \n  # Get number of distinct values per variable\n  dplyr::summarise(dplyr::across(dplyr::everything(), ~ dplyr::n_distinct(.))) |&gt; \n  # Turn df into long format for easy filtering\n  tidyr::pivot_longer(dplyr::everything(), \n                      names_to = \"variable\", \n                      values_to = \"n\") |&gt; \n  # Filter out variables with 10 or less distinct values\n  dplyr::filter(n &lt;= 10) |&gt;\n  # Extract the names of these variables\n  dplyr::pull('variable')\n\ncat(\"Variables with less than 10 distinct values:\", cat_vars)\n\n\nVariables with less than 10 distinct values: geo500h1id geo500h3id lgm vszone\n\n\nNow that we have the names of the categorical values, we can mutate these columns in our df using the base function as.factor():\n\n\nCode\nfinal_data &lt;- \n  final_data |&gt; \n  dplyr::mutate(dplyr::across(cat_vars, ~ as.factor(.)))"
  },
  {
    "objectID": "02-data_preparation.html#checking-missing-data",
    "href": "02-data_preparation.html#checking-missing-data",
    "title": "2  Preparing Raster Data",
    "section": "2.2 Checking missing data",
    "text": "2.2 Checking missing data\nWe are almost done with our data preparation, we just need to reduce it to sampling locations for which we have a decent amount of data on the covariates. Else, we blow up the model calibration with data that is not informative enough.\n\n\nCode\n# Get number of rows to calculate percentages\nn_rows &lt;- nrow(final_data)\n\n# Get number of distinct values per variable\nfinal_data |&gt; \n  dplyr::summarise(dplyr::across(dplyr::everything(), \n                                 ~ length(.) - sum(is.na(.)))) |&gt; \n  tidyr::pivot_longer(dplyr::everything(), \n                      names_to = \"variable\", \n                      values_to = \"n\") |&gt;\n  dplyr::mutate(perc_available = round(n/n_rows *100)) |&gt; \n  dplyr::arrange(perc_available) |&gt; \n  head(10) |&gt; \n  knitr::kable()\n\n\n\n\n\nvariable\nn\nperc_available\n\n\n\n\nph.30.50\n856\n81\n\n\nph.10.30\n866\n82\n\n\nph.50.100\n859\n82\n\n\ntimeset\n871\n83\n\n\nph.0.10\n870\n83\n\n\ndclass\n1006\n96\n\n\nsite_id_unique\n1052\n100\n\n\nx\n1052\n100\n\n\ny\n1052\n100\n\n\ndataset\n1052\n100\n\n\n\n\n\nThis looks good, we have no variable with a substantial amount of missing data. Generally, only pH measurements are lacking, which we should keep in mind when making predictions and inferences. Another great way to explore your data, is using the {visdat} package:\n\n\nCode\nfinal_data |&gt; visdat::vis_miss()\n\n\n\n\n\nAlright, we see that we are not missing a lot of data for any variable and in total only 1% of our data is NA. That is good enough! We do not have to modify the dataframe any further and can save it for further analysis."
  },
  {
    "objectID": "02-data_preparation.html#save-data",
    "href": "02-data_preparation.html#save-data",
    "title": "2  Preparing Raster Data",
    "section": "2.3 Save data",
    "text": "2.3 Save data\n\n\nCode\nsaveRDS(final_data, \n        here::here(\"data/bern_sampling_locations_with_covariates.rds\"))"
  },
  {
    "objectID": "03-model_fit.html#load-data",
    "href": "03-model_fit.html#load-data",
    "title": "3  Fitting a Random Forest Model",
    "section": "3.1 Load data",
    "text": "3.1 Load data\nIn the previous Chapter, we create a dataframe that holds information on the soil sampling locations and the covariates that we extracted for these positions. Let’s load this datafarme into our environment\n\n\nCode\ndata_clean &lt;- readRDS(here::here(\"data/bern_sampling_locations_with_covariates.rds\"))\n\nhead(data_clean) |&gt; knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsite_id_unique\ntimeset\nx\ny\ndataset\ndclass\nwaterlog.30\nwaterlog.50\nwaterlog.100\nph.0.10\nph.10.30\nph.30.50\nph.50.100\nbe_gwn25_hdist\nbe_gwn25_vdist\ncindx10_25\ncindx50_25\ngeo500h1id\ngeo500h3id\nlgm\nlsf\nmrrtf25\nmrvbf25\nmt_gh_y\nmt_rr_y\nmt_td_y\nmt_tt_y\nmt_ttvar\nNegO\nPosO\nprotindx\nSe_alti2m_std_50c\nSe_conv2m\nSe_curv25m\nSe_curv2m_fmean_50c\nSe_curv2m_fmean_5c\nSe_curv2m_s60\nSe_curv2m_std_50c\nSe_curv2m_std_5c\nSe_curv2m\nSe_curv50m\nSe_curv6m\nSe_curvplan25m\nSe_curvplan2m_fmean_50c\nSe_curvplan2m_fmean_5c\nSe_curvplan2m_s60\nSe_curvplan2m_s7\nSe_curvplan2m_std_50c\nSe_curvplan2m_std_5c\nSe_curvplan2m\nSe_curvplan50m\nSe_curvprof25m\nSe_curvprof2m_fmean_50c\nSe_curvprof2m_fmean_5c\nSe_curvprof2m_s60\nSe_curvprof2m_s7\nSe_curvprof2m_std_50c\nSe_curvprof2m_std_5c\nSe_curvprof2m\nSe_curvprof50m\nSe_diss2m_50c\nSe_diss2m_5c\nSe_e_aspect25m\nSe_e_aspect2m_5c\nSe_e_aspect2m\nSe_e_aspect50m\nSe_MRRTF2m\nSe_MRVBF2m\nSe_n_aspect2m_50c\nSe_n_aspect2m_5c\nSe_n_aspect2m\nSe_n_aspect50m\nSe_n_aspect6m\nSe_NO2m_r500\nSe_PO2m_r500\nSe_rough2m_10c\nSe_rough2m_5c\nSe_rough2m_rect3c\nSe_SAR2m\nSe_SCA2m\nSe_slope2m_fmean_50c\nSe_slope2m_fmean_5c\nSe_slope2m_s60\nSe_slope2m_s7\nSe_slope2m_std_50c\nSe_slope2m_std_5c\nSe_slope2m\nSe_slope50m\nSe_slope6m\nSe_toposcale2m_r3_r50_i10s\nSe_tpi_2m_50c\nSe_tpi_2m_5c\nSe_tri2m_altern_3c\nSe_tsc10_2m\nSe_TWI2m_s15\nSe_TWI2m_s60\nSe_TWI2m\nSe_vrm2m_r10c\nSe_vrm2m\nterrTextur\ntsc25_18\ntsc25_40\nvdcn25\nvszone\nx30\ny30\nx60\ny60\n\n\n\n\n4_26-In-005\nd1968_1974_ptf\n2571994\n1203001\nvalidation\npoor\n0\n0\n1\n6.071733\n6.227780\n7.109235\n7.214589\n234.39087\n1.2986320\n-10.62191\n-6.9658718\n6\n0\n7\n0.0770846\n0.0184651\n4.977099\n1316.922\n9931.120\n58\n98\n183\n1.569110\n1.534734\n0.0159717\n0.3480562\n-40.5395088\n-0.0014441\n-0.0062570\n0.0175912\n0.0002296\n2.9204133\n1.1769447\n-1.9364884\n0.0031319\n-0.5886537\n-0.0042508\n-0.0445323\n-0.0481024\n-0.0504083\n-0.1655090\n1.5687343\n0.6229440\n-1.0857303\n0.0007920\n-0.0028067\n-0.0382753\n-0.0656936\n-0.0506380\n-0.0732220\n1.6507173\n0.7082230\n0.8507581\n-0.0023399\n0.3934371\n0.1770810\n-0.9702092\n-0.7929600\n-0.5661940\n-0.9939429\n5.930607\n6.950892\n-0.2840056\n-0.6084610\n-0.2402939\n-0.0577110\n-0.7661251\n1.562085\n1.548762\n0.3228087\n0.2241062\n0.2003846\n4.000910\n16.248077\n0.9428899\n0.6683306\n0.9333237\n0.7310556\n0.8815832\n0.3113754\n1.1250136\n0.3783818\n0.5250366\n0\n-0.0940372\n-0.0583917\n10.319408\n0.4645128\n0.0032796\n0.0049392\n0.0011592\n0.000125\n0.0002450\n0.6248673\n0.3332805\n1.784737\n65.62196\n6\n1625912\n2327826\n244167.6\n2828913\n\n\n4_26-In-006\nd1974_1978\n2572149\n1202965\ncalibration\npoor\n0\n1\n1\n6.900000\n6.947128\n7.203502\n7.700000\n127.41681\n1.7064546\n-10.87862\n-11.8201790\n6\n0\n7\n0.0860347\n0.0544361\n4.975796\n1317.000\n9931.672\n58\n98\n183\n1.568917\n1.533827\n0.0204794\n0.1484705\n19.0945148\n-0.0190294\n0.0021045\n0.0221433\n0.0000390\n3.8783867\n4.3162045\n2.1377332\n-0.0171786\n0.1278165\n-0.0119618\n-0.0501855\n-0.3270764\n-0.1004921\n-0.5133076\n2.0736780\n2.2502327\n-0.3522736\n-0.0073879\n0.0070676\n-0.0522900\n-0.3492197\n-0.1005311\n-0.4981292\n2.1899190\n2.4300070\n-2.4900069\n0.0097907\n0.4014700\n0.7360508\n0.5683194\n0.8753148\n-0.3505180\n0.3406741\n5.984921\n6.984581\n-0.5732749\n0.4801802\n0.4917848\n-0.4550385\n0.7722272\n1.543384\n1.558683\n0.2730940\n0.2489859\n0.2376962\n4.001326\n3.357315\n1.0895698\n0.9857153\n1.0231543\n1.0398037\n1.0152543\n0.5357812\n1.3587183\n0.0645478\n0.5793087\n0\n-0.0014692\n0.0180000\n12.603136\n0.5536283\n0.0070509\n0.0067992\n0.0139006\n0.000300\n0.0005389\n0.7573612\n0.3395441\n1.832904\n69.16074\n6\n1626064\n2327873\n244276.3\n2829029\n\n\n4_26-In-012\nd1974_1978\n2572937\n1203693\ncalibration\nmoderate\n0\n1\n1\n6.200000\n6.147128\n5.603502\n5.904355\n143.41533\n0.9372618\n22.10210\n0.2093917\n6\n0\n7\n0.0737963\n3.6830916\n4.986864\n1315.134\n9935.438\n58\n98\n183\n1.569093\n1.543057\n0.0048880\n0.1112066\n-9.1396294\n0.0039732\n0.0009509\n0.0431735\n0.0034232\n0.7022317\n0.4170935\n-0.4178924\n-0.0026431\n-0.0183221\n0.0015183\n-0.0079620\n0.0053904\n-0.0091239\n-0.0110896\n0.3974485\n0.2292406\n-0.2168447\n-0.0013561\n-0.0024548\n-0.0089129\n-0.0377831\n-0.0125471\n-0.0052359\n0.4158890\n0.2700820\n0.2010477\n0.0012870\n0.6717541\n0.4404107\n-0.6987815\n-0.3866692\n-0.1960597\n-0.7592779\n5.953919\n6.990917\n-0.3006475\n-0.9221049\n-0.9633239\n-0.3257418\n-0.9502072\n1.565405\n1.563151\n0.2305476\n0.2182523\n0.1434273\n4.000320\n11.330072\n0.5758902\n0.5300468\n0.5107915\n0.5744110\n0.4975456\n0.2001768\n0.7160403\n0.1311051\n0.4620202\n0\n0.0340407\n-0.0145804\n7.100000\n0.4850160\n0.0021498\n0.0017847\n0.0011398\n0.000000\n0.0000124\n0.7978453\n0.4455501\n1.981526\n63.57096\n6\n1626382\n2328897\n244039.8\n2830075\n\n\n4_26-In-014\nd1974_1978\n2573374\n1203710\nvalidation\nwell\n0\n0\n0\n6.600000\n6.754607\n7.200000\n7.151129\n165.80418\n0.7653937\n-20.11569\n-7.7729993\n6\n0\n7\n0.0859686\n0.0075817\n5.285522\n1315.160\n9939.923\n58\n98\n183\n1.569213\n1.542792\n0.0064054\n0.3710849\n-0.9318936\n-0.0371234\n0.0029348\n-0.1056513\n0.0127788\n1.5150748\n0.2413423\n-0.0289909\n0.0020990\n-0.0706228\n-0.0113604\n-0.0301961\n-0.0346193\n-0.0273140\n-0.0343277\n0.8245047\n0.1029889\n-0.0272214\n-0.0041158\n0.0257630\n-0.0331309\n0.0710320\n-0.0400928\n0.0529446\n0.8635767\n0.1616543\n0.0017695\n-0.0062147\n0.4988544\n0.4217250\n-0.8485889\n-0.8657616\n-0.8836724\n-0.8993938\n4.856076\n6.964162\n-0.5735765\n-0.4998477\n-0.4677161\n-0.4121092\n-0.4782534\n1.562499\n1.562670\n0.3859352\n0.2732429\n0.1554769\n4.000438\n42.167496\n0.8873205\n0.8635756\n0.9015982\n0.8518201\n0.5767300\n0.2149791\n0.8482135\n0.3928713\n0.8432562\n0\n0.0686932\n-0.0085602\n8.303085\n0.3951114\n0.0008454\n0.0021042\n0.0000000\n0.000100\n0.0000857\n0.4829135\n0.4483251\n2.113142\n64.60535\n6\n1626752\n2329130\n244243.6\n2830462\n\n\n4_26-In-015\nd1968_1974_ptf\n2573553\n1203935\nvalidation\nmoderate\n0\n0\n1\n6.272715\n6.272715\n6.718392\n7.269008\n61.39244\n1.0676192\n-55.12566\n-14.0670462\n6\n0\n7\n0.0650000\n0.0007469\n5.894688\n1315.056\n9942.032\n58\n98\n183\n1.570359\n1.541979\n0.0042235\n0.3907509\n4.2692256\n0.0378648\n0.0022611\n-0.1020419\n0.0161510\n3.6032522\n1.8169731\n0.6409346\n0.0346340\n0.0476020\n0.0378154\n-0.0179657\n-0.0137853\n-0.0146946\n0.0060875\n1.4667766\n0.9816071\n0.2968794\n0.0337645\n-0.0000494\n-0.0202268\n0.0882566\n-0.0308456\n0.0929077\n2.6904552\n1.0218329\n-0.3440553\n-0.0008695\n0.6999696\n0.3944107\n-0.8918364\n-0.8864348\n-0.7795515\n-0.4249992\n4.130917\n6.945287\n0.4304937\n0.4614536\n0.5919228\n0.6559467\n0.4574654\n1.550528\n1.562685\n0.4330348\n0.3299487\n0.1889674\n4.000948\n5.479310\n1.8937486\n1.2098556\n1.5986075\n1.2745584\n2.7759163\n0.5375320\n1.2301254\n0.3582314\n1.1426100\n0\n0.3005829\n0.0061576\n10.110727\n0.5134069\n0.0043268\n0.0045225\n0.0054557\n0.000200\n0.0002062\n0.6290755\n0.3974232\n2.080674\n61.16533\n6\n1626795\n2329415\n244138.2\n2830730\n\n\n4_26-In-016\nd1968_1974_ptf\n2573310\n1204328\ncalibration\npoor\n0\n0\n1\n6.272715\n6.160700\n5.559031\n5.161655\n310.05014\n0.1321367\n-17.16055\n-28.0693741\n6\n0\n7\n0.0731646\n0.0128017\n5.938320\n1315.000\n9940.597\n58\n98\n183\n1.569434\n1.541606\n0.0040683\n0.1931891\n-0.1732794\n-0.1602274\n-0.0035833\n-0.1282881\n0.0003549\n1.5897882\n0.8171870\n0.0318570\n-0.0123340\n0.0400775\n-0.0813964\n-0.0049875\n0.0320331\n-0.0049053\n0.0374298\n0.7912259\n0.3455668\n0.0100844\n-0.0059622\n0.0788309\n-0.0014042\n0.1603212\n-0.0052602\n0.0867119\n1.0207798\n0.6147888\n-0.0217726\n0.0063718\n0.3157751\n0.5292308\n-0.8766075\n0.5905659\n0.8129975\n0.1640853\n2.030315\n6.990967\n0.6325440\n0.8054439\n0.5820994\n0.7448481\n0.6081498\n1.563066\n1.552568\n0.3688371\n0.2607146\n0.1763995\n4.000725\n13.499996\n1.0418727\n0.8515157\n1.2106605\n0.8916541\n1.2163279\n0.4894866\n1.0906221\n0.2049688\n0.7156029\n0\n-0.0910767\n0.0034276\n9.574804\n0.3864355\n0.0001476\n0.0003817\n0.0000000\n0.000525\n0.0001151\n0.6997021\n0.4278295\n2.041467\n55.78354\n6\n1626388\n2329634\n243676.4\n2830716"
  },
  {
    "objectID": "03-model_fit.html#preparations",
    "href": "03-model_fit.html#preparations",
    "title": "3  Fitting a Random Forest Model",
    "section": "3.2 Preparations",
    "text": "3.2 Preparations\nBefore we can fit the model, we have to specify a few settings. First, we have to specify our response and predictor variables. Then, we have to split our dataset into a calibration and a validation set. Random Forest models cannot deal with NA values, so we have to remove these from our calibration set.\n\n\nCode\n# Specify response: The pH in the top 10cm\nresponse &lt;- \"ph.0.10\"\n\n# Specify predictors: Remove soil sampling information\npredictors &lt;- \n  data_clean |&gt; \n  dplyr::select(-response,                             # Remove response variable\n                -site_id_unique,                       # Remove site ID (no information)\n                -tidyr::starts_with(\"ph\"),             # No pH information\n                -tidyr::starts_with(\"waterlog\"),       # No water-status information\n                -dclass,                               # No water-status information\n                -dataset) |&gt;                           # Remove calibratoin/validation information\n  names()\n\ncat(\"The response is:\", response,\n    \"\\nThe predictors are:\", paste0(predictors[1:8], sep = \", \"), \"...\")\n\n\nThe response is: ph.0.10 \nThe predictors are: timeset,  x,  y,  be_gwn25_hdist,  be_gwn25_vdist,  cindx10_25,  cindx50_25,  geo500h1id,  ...\n\n\n\n\nCode\n# Split dataset into calibration and validation\ndata_cal &lt;- data_clean |&gt; dplyr::filter(dataset == \"calibration\")\ndata_val &lt;- data_clean |&gt; dplyr::filter(dataset == \"validation\")\n\n# Filter out any NA to avoid error when running a Random Forest\ndata_cal &lt;- data_cal |&gt; tidyr::drop_na()\ndata_val &lt;- data_val |&gt; tidyr::drop_na()\n\n# A little bit of verbose output:\nn_tot &lt;- nrow(data_cal) + nrow(data_val)\n\nperc_cal &lt;- (nrow(data_cal) / n_tot) |&gt; round(2) * 100\nperc_val &lt;- (nrow(data_val) / n_tot) |&gt; round(2) * 100\n\ncat(\"For model training, we have a calibration / validation split of: \",\n    perc_cal, \"/\", perc_val, \"%\")\n\n\nFor model training, we have a calibration / validation split of:  75 / 25 %\n\n\nAlright, this looks all good. We have our response and predictor variables saved for easy access later on and the 75/25 split of calibration and validation data looks good too. We can now move on to model fitting!"
  },
  {
    "objectID": "03-model_fit.html#model-fitting",
    "href": "03-model_fit.html#model-fitting",
    "title": "3  Fitting a Random Forest Model",
    "section": "3.3 Model fitting",
    "text": "3.3 Model fitting\nTo fit a Random Forest model that predicts the soil pH in the top 10cm, we are looking at different model setups. These setups always train a Random Forest model but differ in the complexity that we intentionally add to improve the final model. If you need a recap on Random Forests, have a look at the introduction given in AGDS 1.\n\n3.3.1 Basic model\nLet’s start with the basic model, where we use the {ranger} package with the pre-defined hyperparameters.\n\n\nCode\n# ranger() crashes when using tibbles, so we are using the\n# base R notation to enter the data\n\nrf_basic &lt;- ranger::ranger( \n  y = data_cal[, response],   # Response variable\n  x = data_cal[, predictors], # Predictor variables\n  seed = 42,                  # Specify the seed for randomization to reproduce the same model again\n  num.threads = parallel::detectCores() - 1) # Use all but one CPU core for quick model training\n\n# Print a summary of fitted model\nrf_basic |&gt; print()\n\n\nRanger result\n\nCall:\n ranger::ranger(y = data_cal[, response], x = data_cal[, predictors],      seed = 42, num.threads = parallel::detectCores() - 1) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      605 \nNumber of independent variables:  98 \nMtry:                             9 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       0.2804814 \nR squared (OOB):                  0.5252541 \n\n\n\n\n\n\n\n\nPredicting Categories with Random Forests\n\n\n\nIf our response variable was a categorical and not a continuous variable, we would have to set the argument probability = TRUE. The output would then be a probability map from 0-100%.\n\n\nAlthough we only used the pre-defined parameters, we already get a fairly good out-of-bag (OOB) \\(R^2\\) of 0.53 and a MSE of 0.28. Let’s see how we can improve our model further.\n\n\n3.3.2 Model with weights\nSometimes we know that a subset of our dataset is more trustworthy than the rest. For example, when you are using a gap-filling technique to interpolate data, that gap-filled data is less trustworthy than the actually measured data. Informing the model algorithm that it should weigh certain data entries more than other can change the importance of variables and the final model performance.\nIn our dataset, we have information on whether the pH values were measured in the field - which is less precise - or in the lab. Also, we have to different lab methods. All of this information is held in the suffix of the timeset variable, so let’s assign weights according on the quality of the pH data as follows: 1 for CaCl\\(_2\\) lab measurement (no suffix), 0.9 for pedotransfer from another lab method (suffix _ptf), and 0.7 for field data (suffix _field). For this, we create a weight-matching vector:\n\n\nCode\nweights &lt;- \n  data_cal |&gt;\n  dplyr::mutate(\n    # Create a new variable 'weight' which holds only 1's\n    w = 1,\n    # Check the suffix in each row and if true, give a new weight. If false, keep the old weight.\n    w = ifelse(stringr::str_detect(timeset, \"_field\"), 0.9, w),\n    w = ifelse(stringr::str_detect(timeset, \"_ptf\"), 0.7, w)\n  )\n\n# Quality check if everything worked:\nset.seed(42)\n\nweights |&gt; \n  dplyr::select(timeset, w) |&gt; \n  dplyr::slice_sample(n = 8) |&gt;   # Pick 8 random rows\n  knitr::kable()\n\n\n\n\n\ntimeset\nw\n\n\n\n\nd1979_2010\n1.0\n\n\nd1968_1974_field\n0.9\n\n\nd1968_1974_field\n0.9\n\n\nd1968_1974_field\n0.9\n\n\nd1968_1974_field\n0.9\n\n\nd1968_1974_ptf\n0.7\n\n\nd1968_1974_field\n0.9\n\n\nd1968_1974_field\n0.9\n\n\n\n\n\nIt is always a good idea to do quality checks when wrangling! Here we see that our weight attribution code worked as expected, so we can move on to model fitting.\n\n\nCode\nrf_weighted &lt;- ranger::ranger( \n  y = data_cal[, response],      # Response variable\n  x = data_cal[, predictors],    # Predictor variables\n  case.weights = weights[, \"w\"], # Add weights to input\n  seed = 42,                     # Specify seed for randomization to reproduce the same model again\n  num.threads = parallel::detectCores() - 1) # Use all but one CPU core for quick model training\n\n# Print a summary of fitted model\nrf_weighted |&gt; print()\n\n\nRanger result\n\nCall:\n ranger::ranger(y = data_cal[, response], x = data_cal[, predictors],      case.weights = weights[, \"w\"], seed = 42, num.threads = parallel::detectCores() -          1) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      605 \nNumber of independent variables:  98 \nMtry:                             9 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       0.2874622 \nR squared (OOB):                  0.5134383 \n\n\nNot much has changed compared to our previous model. We see that the \\(R^2\\) and MSE got negligibly worse but as a trade-off we gained more trust in our model.\n\n\n3.3.3 Variables of importance\nOur model has 98 variables but we have no idea if each of them should really be in the model and if we are not just fitting noise in the dataset. To investigate this issue, the ranger() function takes an argument called importance. We can set this argument either to follow the permutation method, whereby the algorithm randomly permutes values of each variable and measures the resulting decrease in model accuracy. A larger decrease indicates a more important variable. If the code runs slow, you can also use the faster impurity method (see more information here).\nAssessing the variable importance gives us a feeling for what variables we should keep or drop from the dataset. The ranger-model stores this information if we enter a importance method. The code below accesses the model’s variable importance and sorts the variables with decreasing importance.\n\n\nCode\n# Let's run the weighted model again but with recording the variable importance\nrf_weighted &lt;- ranger::ranger( \n  y = data_cal[, response],     # Response variable\n  x = data_cal[, predictors],   # Predictor variables\n  case.weights = weights[, \"w\"],# Add weights to input\n  importance   = \"permutation\", # Pick permutation to calculate variable importance\n  seed = 42,                    # Specify seed for randomization to reproduce the same model again\n  num.threads = parallel::detectCores() - 1) # Use all but one CPU core for quick model training\n\n# Writing functions here for re-usability:\nget_vi &lt;- function(rf_model){\n  \n  # Extract the variable importance and create a long tibble\n  vi &lt;- \n    rf_model$variable.importance |&gt;\n    dplyr::bind_rows() |&gt; \n    tidyr::pivot_longer(cols = dplyr::everything(), names_to = \"variable\")\n  \n  return(vi)\n}\n\nplot_vi &lt;- function(rf_model){\n  \n  # Plot variable importance, ordered by decreasing value\n  vi &lt;- get_vi(rf_model)\n  \n  p &lt;- \n    vi |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = reorder(variable, value), y = value)) +\n    ggplot2::geom_bar(stat = \"identity\", fill = \"grey50\", width = 0.75) + \n    ggplot2::labs(\n      y = \"Change in OOB MSE after permutation\", \n      x = \"\",\n      title = \"Change in OOB MSE after permutation\") +\n    # ggplot2::coord_flip() +\n    ggplot2::theme_classic() +\n    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 90, vjust = 0.5, hjust=1))\n  \n  return(p)\n}\n\nplot_vi(rf_weighted)\n\n\n\n\n\nWhat do we see here? The y-axis shows the decrease in model performance when the respective variable is randomly permuted and, therefore, denotes the importance of a variable. The higher the value, the stronger the effect of permutation on the model performance, the more important the variable. Also, we see that a large part of our covariates have practically no power to predict the pH and can therefore be removed from the model. But how do we determine what variable to pick for our final model? Do we want a maximum number of predictors? Do we want a set of the top n predictors that make up a certain percentage of the total variable importance?\nOne common option to generalize variable selection is the “Boruta-Algorithm”, which itself is based Random Forests. In essence, the algorithm creates “shadows” of your original data, where each of the predictor value is randomly permuted, which destroys the predictive power of the variable. Then, the algorithm iterates over these “shadows” and assess for each variable whether its permutation has a substantial effect on the model performance or not. E.g., if a model trained on a variable’s shadow performs constantly worse than when trained on the original values, that variable is assessed as important. The algorithm categorizes all variables into “to reject”, “to consider”, and “to keep”. Luckily, we do not have to write this algorithm ourselves but can use the {Boruta} package:\n\n\nCode\nset.seed(42)\nbor &lt;- \n  Boruta::Boruta(\n    y = data_cal[, response], \n    x = data_cal[, predictors],\n    maxRuns = 50, # Number of iterations. Set to 30 or lower if it takes too long\n    num.threads = parallel::detectCores()-1)\n\n# Plot variable importance, the Boruta-output can be directly fed into base R plot()\npar(oma = c(8,3,2,2)) # enlarge plot below for long variable labels\nplot(bor, \n     xlab = \"\", \n     ylab = \"Importance\",\n     las = 2,\n     )\n\n\n\n\n\n\n\nCode\n# Check whether the most important variables from Boruta-Algorithm are similar as the\n# important variables from the weighted Random Forest model\nbor_top10 &lt;- \n  Boruta::attStats(bor) |&gt; \n  tibble::rownames_to_column() |&gt; \n  dplyr::arrange(dplyr::desc(meanImp)) |&gt; \n  dplyr::slice_head(n = 10) |&gt; \n  dplyr::pull(rowname)\n\nvi &lt;- get_vi(rf_weighted)\nvi_top10 &lt;- \n  vi |&gt; \n  dplyr::slice_head(n = 10) |&gt; \n  dplyr::pull(variable)\n\ncbind(vi_top10, bor_top10) |&gt; \n  knitr::kable(col.names = c(\"RF Top 10\", \"Boruta Top 10\"))\n\n\n\n\n\nRF Top 10\nBoruta Top 10\n\n\n\n\ntimeset\ntimeset\n\n\nx\ny30\n\n\ny\ny\n\n\nbe_gwn25_hdist\nmt_rr_y\n\n\nbe_gwn25_vdist\ny60\n\n\ncindx10_25\nx\n\n\ncindx50_25\nx30\n\n\ngeo500h1id\nmt_tt_y\n\n\ngeo500h3id\nx60\n\n\nlgm\nSe_TWI2m_s15\n\n\n\n\n\nWe see that apart from the timeset variable, the variable importance calculated by the Boruta-Algorithm differs quite a bit, compared to the simple variable importance assessment built into the ranger() function. To move forward, let’s only keep variables that were classified as “to keep” or “to consider” by the Boruta-Algorithm.\n\n\nCode\npredictors_bor &lt;- \n  bor$finalDecision |&gt; \n  as.data.frame(nm = \"assessment\") |&gt; \n  tibble::rownames_to_column(var = \"variable\") |&gt; \n  dplyr::filter(assessment != \"Rejected\") |&gt; \n  dplyr::pull(variable)\n\n\n\n\n3.3.4 Hyperparameter Tuning\nA Random Forest model has multiple hyperparameters that we can tune to improve the model performance. Commonly, we are tuning the numbers of variables that are considered at each node mtry and the minimum number of observations in a leaf node min.node.size. To facilitate the tuning routine, we are using the {caret} package, which is a wrapper for many different statistical models. Also, we are adding a 5-fold cross-validation to improve model performance.\n\n\nCode\nopt_mtry &lt;- (floor(length(predictors_bor) / 3))\n\ntune_grid &lt;- \n  expand.grid(\n    splitrule = \"variance\", # Keep split rule the same\n    min.node.size = c(5, 10),\n    mtry = seq(opt_mtry - 12,\n                opt_mtry + 12,\n                6)\n    )\n\ntune_grid |&gt; knitr::kable()\n\n\n\n\n\nsplitrule\nmin.node.size\nmtry\n\n\n\n\nvariance\n5\n7\n\n\nvariance\n10\n7\n\n\nvariance\n5\n13\n\n\nvariance\n10\n13\n\n\nvariance\n5\n19\n\n\nvariance\n10\n19\n\n\nvariance\n5\n25\n\n\nvariance\n10\n25\n\n\nvariance\n5\n31\n\n\nvariance\n10\n31\n\n\n\n\n\n\n\nCode\n# Model training with cv\nrf_caret_cv &lt;- \n    caret::train(\n        y = data_cal[, response], \n        x = data_cal[, predictors_bor],\n        # case.weights = weights[, \"w\"],\n        tuneGrid = tune_grid,\n        method = \"ranger\",\n        trControl = caret::trainControl(method = \"cv\", number = 5)\n    )\n\nrf_caret_cv\n\n\nRandom Forest \n\n605 samples\n 57 predictor\n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 484, 484, 483, 485, 484 \nResampling results across tuning parameters:\n\n  min.node.size  mtry  RMSE       Rsquared   MAE      \n   5              7    0.5217069  0.5443577  0.4200393\n   5             13    0.5165682  0.5524160  0.4165533\n   5             19    0.5118972  0.5601600  0.4123606\n   5             25    0.5107955  0.5617213  0.4105809\n   5             31    0.5082873  0.5658401  0.4076707\n  10              7    0.5211940  0.5465129  0.4187897\n  10             13    0.5135841  0.5585009  0.4129460\n  10             19    0.5094686  0.5648549  0.4102757\n  10             25    0.5095817  0.5641810  0.4093945\n  10             31    0.5105233  0.5619128  0.4104439\n\nTuning parameter 'splitrule' was held constant at a value of variance\nRMSE was used to select the optimal model using the smallest value.\nThe final values used for the model were mtry = 31, splitrule = variance\n and min.node.size = 5.\n\n\nCode\n# Model training with weights\n# rf_caret_w &lt;- \n#     caret::train(\n#       y = data_cal[, response], \n#       x = data_cal[, predictors_bor],\n#       case.weights = weights[, \"w\"],\n#       tuneGrid = tune_grid,\n#       method = \"ranger\",\n#       # trControl = caret::trainControl(method = \"cv\", number = 5)\n#   )\n# rf_caret_w$bestTune\n\n\n\n\n\n\n\n\nCV with weights\n\n\n\nUnfortuntately, {caret} handles the weights wrong during CV, which throws an error when trying to use weights alongside CV. As a work-around, one could write the CV by hand and run caret with the weights as input. As we aim for generalizability of our model, we are preferring the cross-validated over the weighted model.\n\n\nFrom this model output, we can see that the best model had a mtry = 31, a min.node.size = 10. Since we are going to use functions from the {ranger} package for the model interpretation in the next Chapter, we have to first rerun our final model with range() and then save all relevant data for further analysis.\n\n\nCode\nrf_final &lt;- \n  ranger::ranger( \n    y = data_cal[, response],         # Response variable\n    x = data_cal[, predictors_bor],   # Predictor variables\n    case.weights = weights[, \"w\"],# Add weights to input\n    importance   = \"permutation\", # Pick permutation to calculate variable importance\n    mtry = rf_caret_cv$finalModel$mtry,\n    min.node.size = rf_caret_cv$finalModel$min.node.size,\n    splitrule = \"variance\",\n    seed = 42,                    # Specify seed for randomization to reproduce the same model again\n    num.threads = parallel::detectCores() - 1 # Use all but one CPU core for quick model training\n  )\n\nprint(rf_final)\n\n\nRanger result\n\nCall:\n ranger::ranger(y = data_cal[, response], x = data_cal[, predictors_bor],      case.weights = weights[, \"w\"], importance = \"permutation\",      mtry = rf_caret_cv$finalModel$mtry, min.node.size = rf_caret_cv$finalModel$min.node.size,      splitrule = \"variance\", seed = 42, num.threads = parallel::detectCores() -          1) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      605 \nNumber of independent variables:  57 \nMtry:                             31 \nTarget node size:                 5 \nVariable importance mode:         permutation \nSplitrule:                        variance \nOOB prediction error (MSE):       0.2577789 \nR squared (OOB):                  0.5636805"
  },
  {
    "objectID": "03-model_fit.html#model-interpretation",
    "href": "03-model_fit.html#model-interpretation",
    "title": "3  Fitting a Random Forest Model",
    "section": "3.4 Model interpretation",
    "text": "3.4 Model interpretation\n\n3.4.1 Variable importance\n{Similar as already done above for variable selection.}\n\n\nCode\nplot_vi(rf_final)\n\n\n\n\n\n\n\n3.4.2 Partial dependence plots\nPartial dependence plots (PDP) show the marginal effect that a given predictor has on the response, when the effects of all other predictors are accounted for. We know that not all variables are very influential, so we look only at the top give variables:\n\n\nCode\n# Get the names of the 5 most important variables\n\n# Top n variables to create PDPs for\ntop_n &lt;- 5\n\n# Get top variables\ntop_vars &lt;- \n  get_vi(rf_final) |&gt; \n  dplyr::slice_head(n = top_n) |&gt; \n  dplyr::pull(variable)\n\n# Create a small loop to extract the predictor values and y_hat\n# Create separate df for numerical and for categorical variables\npdp_data_num &lt;- tibble::tibble()\npdp_data_cat &lt;- tibble::tibble()\n\nfor (i_var in top_vars) {\n  i_data &lt;- \n    pdp::partial(rf_final, \n                 pred.var = i_var, # select one variable you are interessted in \n                 train = data_cal[, c(response, predictors_bor)]) |&gt; \n    tidyr::pivot_longer(cols = i_var, names_to = \"variable\", values_to = \"x\")\n  \n  if (is.character(i_data[['x']])) {\n    pdp_data_cat &lt;- rbind(pdp_data_cat, i_data)  \n    \n  } else {\n    pdp_data_num &lt;- rbind(pdp_data_num, i_data)  \n    \n  }\n}\n\n# Plot numerical variables\npdp_data_num |&gt; \n  ggplot2::ggplot() +\n  ggplot2::geom_line(aes(x = x, y = yhat)) +\n  ggplot2::facet_wrap(~variable, scales = \"free_x\", nrow = 1) +\n  ggplot2::theme_linedraw() +\n  ggplot2::theme(axis.text.x = element_text(angle = 45, hjust = 1),\n                 panel.grid.minor.x = element_blank()) +\n  ggplot2::labs(y = \"Response [unit of response]\",\n                x = NULL)\n\n\n\n\n\n\n\nCode\n# Plot categorical variables\npdp_data_cat |&gt; \n  ggplot2::ggplot() +\n  ggplot2::geom_point(aes(x = x, y = yhat)) +\n  ggplot2::facet_wrap(~variable, scales = \"free_x\", nrow = 1) +\n  ggplot2::theme_linedraw() +\n  ggplot2::theme(axis.text.x = element_text(angle = 45, hjust = 1),\n                 panel.grid.minor.x = element_blank()) +\n  ggplot2::labs(y = \"Response [unit of response]\",\n                x = NULL)\n\n\n\n\n\n\n\n3.4.3 Save outputs for evaluation\n\n\nCode\n# Save all relevant data for model interpretation\nsaveRDS(rf_final,                   \n        here::here(\"data/rf_for_ph0-10.rds\"))\n\nsaveRDS(data_cal[, c(response, predictors_bor)],\n        here::here(\"data/cal_for_ph0-10.rds\"))\n\nsaveRDS(data_val[, c(response, predictors_bor)],\n        here::here(\"data/val_for_ph0-10.rds\"))\n\nsaveRDS(weights[, \"w\"],\n        here::here(\"data/weights_for_ph0-10.rds\"))"
  },
  {
    "objectID": "04-model_eval.html#load-model-and-data",
    "href": "04-model_eval.html#load-model-and-data",
    "title": "4  Model Analysis",
    "section": "4.1 Load model and data",
    "text": "4.1 Load model and data\n\n\nCode\n# Load best random forest model\nrf &lt;- readRDS(here::here(\"data/rf_for_pH0-10.rds\"))\ndata_cal &lt;- readRDS(here::here(\"data/cal_for_ph0-10.rds\"))\ndata_val &lt;- readRDS(here::here(\"data/val_for_ph0-10.rds\"))\n\n\nOur target area to predict on is defined in the file area_to_be_mapped.tif. Since we only want to predict on a given study area, the TIF file comes with a specification of 0 and one for the area of (no) interest.\n\n\nCode\n# Load area to be predicted\ntarget_raster &lt;- terra::rast(here::here(\"data-raw/geodata/study_area/area_to_be_mapped.tif\"))\n\n# Turn target raster into a dataframe, 1 px = 1 cell\ntarget_df &lt;- as.data.frame(target_raster, xy = TRUE)\n\n# Filter only for area of interest\ntarget_df &lt;- target_df |&gt; dplyr::filter(area_to_be_mapped == 1)\n\n# Display df\nhead(target_df) |&gt; knitr::kable()\n\n\n\n\n\nx\ny\narea_to_be_mapped\n\n\n\n\n2587670\n1219750\n1\n\n\n2587690\n1219750\n1\n\n\n2587090\n1219190\n1\n\n\n2587090\n1219170\n1\n\n\n2587110\n1219170\n1\n\n\n2587070\n1219150\n1\n\n\n\n\n\nNext, we have to load the relevant covariates to run our model:\n\n\nCode\n# Get a list of all covariate file names\ncovariate_files &lt;- \n  list.files(path = here::here(\"data-raw/geodata/covariates/\"), \n             pattern = \".tif$\",\n             recursive = TRUE, \n             full.names = TRUE\n             )\n\n# Filter that list only for the variables used in the RF\nused_cov &lt;- names(rf$variable.importance)\ncov_to_load &lt;- c()\n\nfor (i_var in used_cov) {\n  i &lt;- covariate_files[stringr::str_detect(covariate_files, \n                                           paste0(\"/\", i_var, \".tif\"))]\n  cov_to_load &lt;- append(cov_to_load, i)\n  \n  # cat(\"\\nfor var \", i_var, \" load file: \", i)\n}\n\n# Load all rasters as a stack\ncov_raster &lt;- terra::rast(cov_to_load)\n\n# Get coordinates for which we want data\nsampling_xy &lt;- target_df |&gt; dplyr::select(x, y)\n\n# Extract data from covariate raster stack\ncov_df &lt;-\n  terra::extract(cov_raster,  # The raster we want to extract from\n                 sampling_xy,  # A matrix of x and y values to extract for\n                 ID = FALSE    # To not add a default ID column to the output\n                 )\n\ncov_df &lt;- cbind(sampling_xy, cov_df)\n\n# Add rotated coordinates as when preparing training data:\ncov_df &lt;- \n  cov_df |&gt; \n    dplyr::mutate(\n      x30 = x*cos(30/180*pi) - y*sin(30/180*pi),\n      y30 = x*sin(30/180*pi) + y*cos(30/180*pi),\n      x60 = x*cos(60/180*pi) - y*sin(60/180*pi),\n      y60 = x*sin(60/180*pi) + y*cos(60/180*pi)\n    )\n\n# Attaching reference timeset levels from prepared dataset\nbern_cov &lt;- readRDS(here::here(\"data/bern_sampling_locations_with_covariates.rds\"))\n\ncov_df$timeset &lt;- \"d1979_2010\"\nlevels(cov_df$timeset) &lt;- c(unique(bern_cov$timeset))\n\n# Define numerically encoded categorical variables \ncat_vars &lt;- \n  cov_df |&gt; \n  # Get number of distinct values per variable\n  dplyr::summarise(dplyr::across(dplyr::everything(), ~ dplyr::n_distinct(.))) |&gt; \n  # Turn df into long format for easy filtering\n  tidyr::pivot_longer(dplyr::everything(), \n                      names_to = \"variable\", \n                      values_to = \"n\") |&gt; \n  # Filter out variables with 10 or less distinct values\n  dplyr::filter(n &lt;= 10) |&gt;\n  # Extract the names of these variables\n  dplyr::pull('variable')\n\ncov_df &lt;- \n  cov_df |&gt; \n  dplyr::mutate(dplyr::across(cat_vars, ~ as.factor(.)))\n\n# Reduce dataframe to hold only rows without any NA values\ncov_df &lt;- \n  cov_df |&gt; \n  tidyr::drop_na()\n\n# Display final dataframe\nhead(cov_df) |&gt; knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx\ny\nbe_gwn25_vdist\ncindx50_25\ngeo500h1id\ngeo500h3id\nlsf\nmrvbf25\nmt_gh_y\nmt_rr_y\nmt_td_y\nmt_tt_y\nmt_ttvar\nNegO\nPosO\nprotindx\nSe_alti2m_std_50c\nSe_curv25m\nSe_curv2m_fmean_50c\nSe_curv2m_s60\nSe_curv2m_std_50c\nSe_curv2m_std_5c\nSe_curv50m\nSe_curvplan2m_std_50c\nSe_curvplan2m_std_5c\nSe_curvprof25m\nSe_curvprof2m_s7\nSe_curvprof2m_std_50c\nSe_curvprof2m_std_5c\nSe_curvprof50m\nSe_diss2m_50c\nSe_diss2m_5c\nSe_MRVBF2m\nSe_n_aspect2m_50c\nSe_n_aspect2m_5c\nSe_n_aspect2m\nSe_n_aspect50m\nSe_PO2m_r500\nSe_rough2m_10c\nSe_slope2m_fmean_50c\nSe_slope2m_s60\nSe_slope2m_std_5c\nSe_slope50m\nSe_tpi_2m_50c\nSe_TWI2m_s15\nSe_TWI2m_s60\nSe_TWI2m\nterrTextur\ntsc25_18\ntsc25_40\nvdcn25\nvszone\nx30\ny30\nx60\ny60\ntimeset\n\n\n\n\n2587670\n1219750\n15.664033\n9.219586\n5\n0\n1.6357950\n0.7211104\n1311.320\n10791.72\n57\n94\n183\n1.526693\n1.475333\n0.0650055\n4.784680\n-0.1573657\n0.0024712\n-0.0401642\n5.627444\n8.208909\n-0.0951815\n2.520638\n3.900391\n0.1039651\n-1.1700106\n4.067357\n5.008852\n0.0409964\n0.3920868\n0.7319978\n0.2460670\n0.9587829\n0.9984013\n0.9855098\n0.9959861\n1.499916\n1.2614983\n5.379811\n6.507652\n4.4604211\n5.657930\n-0.1146867\n0.0196044\n0.0193961\n0.0094032\n0.4892213\n0.4671952\n2.447572\n32.42764\n5\n1631113\n2350169\n237500.5\n2850863\nd1979_2010\n\n\n2587690\n1219750\n14.940482\n8.887812\n5\n0\n1.6952833\n0.6501970\n1311.240\n10790.04\n57\n94\n183\n1.519305\n1.479355\n0.0614093\n4.554082\n-0.0033177\n0.0346522\n-0.0067883\n5.807981\n2.624915\n-0.0114668\n2.609372\n1.747575\n0.0623458\n0.3911650\n4.186157\n1.268572\n0.0070421\n0.3616736\n0.4156418\n0.4769361\n0.9681105\n0.9996192\n0.9919428\n0.9949375\n1.481037\n1.1013201\n5.293089\n6.291715\n1.4163034\n5.312412\n-0.5947826\n0.0147714\n0.0177614\n0.0012333\n0.4985980\n0.4697721\n2.450347\n32.34033\n5\n1631130\n2350179\n237510.5\n2850880\nd1979_2010\n\n\n2587090\n1219190\n5.726926\n-11.109116\n4\n0\n0.5349063\n1.4682430\n1310.274\n10723.66\n58\n94\n184\n1.555187\n1.503930\n0.0460703\n1.626563\n0.0084397\n0.0061933\n-0.0022937\n6.824774\n6.073048\n-0.0072457\n2.366981\n1.279673\n-0.0173340\n0.1884064\n5.534662\n5.491115\n0.0054969\n0.5250703\n0.3176954\n1.1235304\n-0.9772032\n0.8215204\n0.9954001\n-0.9600990\n1.494511\n0.5166996\n3.551755\n3.040830\n2.3797400\n1.395017\n-0.0982406\n0.0197626\n0.0162485\n0.0259366\n0.7806686\n0.4930030\n2.233182\n15.32439\n8\n1630891\n2349395\n237695.5\n2850081\nd1979_2010\n\n\n2587090\n1219170\n5.784212\n-12.143552\n4\n0\n0.5427678\n1.4188210\n1310.245\n10721.32\n58\n94\n184\n1.555535\n1.504260\n0.0452300\n1.741869\n0.0117131\n-0.0394273\n0.0330435\n6.898385\n2.127208\n0.0312720\n2.350148\n1.199804\n-0.0020192\n-0.0721385\n5.623002\n1.172386\n-0.0276995\n0.6905439\n0.5443047\n1.1301626\n-0.9925461\n-0.7484674\n-0.4839056\n-0.9521305\n1.545543\n0.5673958\n3.531246\n3.003023\n0.7783145\n1.400111\n0.7135532\n0.0141175\n0.0159906\n0.0154473\n0.7260778\n0.4922101\n2.229970\n15.40787\n8\n1630901\n2349377\n237712.8\n2850071\nd1979_2010\n\n\n2587110\n1219170\n6.106696\n-12.183930\n4\n0\n0.5323660\n1.3493569\n1310.299\n10722.13\n58\n94\n184\n1.555655\n1.504170\n0.0451466\n1.808976\n0.0324950\n-0.0373967\n0.0359804\n7.503298\n2.297817\n0.0834899\n2.387497\n1.301248\n-0.0049620\n-0.0394869\n6.239721\n1.240976\n-0.0469468\n0.6792284\n0.5120147\n1.3914874\n-0.9945219\n-0.9489474\n-0.9524035\n-0.9798594\n1.546788\n0.5236238\n3.856629\n3.079502\n0.4211105\n1.347915\n0.9748727\n0.0122094\n0.0161002\n0.0079080\n0.7223964\n0.4901487\n2.229178\n15.43506\n8\n1630918\n2349387\n237722.8\n2850088\nd1979_2010\n\n\n2587070\n1219150\n5.136146\n-13.059101\n4\n0\n0.4896232\n1.5352163\n1310.168\n10718.23\n58\n94\n184\n1.556895\n1.504168\n0.0449906\n1.885761\n0.1670244\n-0.0237084\n0.0322937\n6.921697\n1.829110\n0.0651237\n2.425535\n1.074812\n-0.1618870\n0.0668136\n5.548432\n0.934908\n-0.0525633\n0.7167594\n0.4836134\n2.5623682\n-0.9945219\n-0.8139611\n-0.1249791\n-0.9608662\n1.547748\n0.4012785\n3.335257\n3.145846\n0.3790899\n2.112438\n0.7557949\n0.0124573\n0.0161766\n0.0134654\n0.6677173\n0.4911794\n2.225173\n15.57539\n8\n1630893\n2349350\n237720.1\n2850043\nd1979_2010"
  },
  {
    "objectID": "04-model_eval.html#create-map-of-predictions",
    "href": "04-model_eval.html#create-map-of-predictions",
    "title": "4  Model Analysis",
    "section": "4.2 Create map of predictions",
    "text": "4.2 Create map of predictions\n\n\nCode\n# Need to load {ranger} because ranger-object is used in predict()\nlibrary(ranger) \n\n# Make predictions using the RF model\nprediction &lt;- \n  predict(rf,              # RF model\n          data = cov_df,   # Predictor data\n          num.threads = parallel::detectCores()-1)\n\n# Attach predictions to dataframe and round them\ncov_df$prediction &lt;- round(prediction$predictions, 2)\n\n\n\n\n\n\n\n\nPredicting Categories with Random Forests\n\n\n\nIf your response variable was a categorical value, you want to predict its probability. You can access these predicted probabilities like this: prediction$predictions[,1].\n\n\n\n\nCode\n# Extract dataframe with coordinates and predictions\ndf_map &lt;- cov_df |&gt; dplyr::select(x, y, prediction)\n\n# Turn dataframe into a raster\nra_predictions &lt;- \n  terra::rast(\n    df_map,                  # Table to be transformed\n    crs = \"+init=epsg:2056\", # Swiss coordinate system\n    extent = terra::ext(cov_raster) # Prescribe same extent as predictor rasters\n            )\n\n\n\n\nCode\n# Let's have a look at our predictions!\n# To have some more flexibility, we can plot this in the ggplot-style as such:\nggplot2::ggplot() +\n  tidyterra::geom_spatraster(data = ra_predictions) +\n  ggplot2::scale_fill_viridis_c(\n    na.value = NA,\n    option = \"viridis\",\n    name = \"pH\"\n    ) +\n  ggplot2::theme_classic() +\n  ggplot2::scale_x_continuous(expand = c(0, 0)) +\n  ggplot2::scale_y_continuous(expand = c(0, 0)) +\n  ggplot2::labs(title = \"Predicted soil pH (0 - 10cm)\")\n\n\n\n\n\n\n\n\n\nCode\n# Save raster as .tif file\nterra::writeRaster(\n  ra_predictions,\n  \"data/ra_predicted_ph0-10.tif\",\n  datatype = \"FLT4S\",  # FLT4S for floats, INT1U for integers (smaller file)\n  filetype = \"GTiff\",  # GeoTiff format\n  overwrite = \"TRUE\"   # Overwrite existing file\n)"
  },
  {
    "objectID": "04-model_eval.html#model-evaluation",
    "href": "04-model_eval.html#model-evaluation",
    "title": "4  Model Analysis",
    "section": "4.3 Model evaluation",
    "text": "4.3 Model evaluation\n\n\n4.3.1 Make predictions\n\n\nCode\n# Need to load {ranger} because ranger-object is used in predict()\nlibrary(ranger) \n\n# Make predictions for validation sites\nprediction &lt;- \n  predict(rf,                # RF model\n          data = data_val,   # Predictor data\n          num.threads = parallel::detectCores()-1)\n\n# Save predictions to validation df\ndata_val$pred &lt;- prediction$predictions\n\n\n\n\n4.3.2 Calculate model metrics\n\n\nCode\n# Calculate error\nerr &lt;- data_val$ph.0.10 - data_val$pred\n\n# Calculate bias\nbias &lt;- mean(err, na.rm = T) |&gt; round(2)\n\n# Calculate RMSE\nrmse &lt;- sqrt(mean(err, na.rm = T)) |&gt; round(2)\n\n# Calculate R2\nr2 &lt;- cor(data_val$ph.0.10, data_val$pred, method = \"pearson\")^2 |&gt; round(2)\n\n\n\n\n4.3.3 Make plots\n\n\nCode\ndata_val |&gt; \n  ggplot2::ggplot(ggplot2::aes(x = pred, y = ph.0.10)) +\n  ggplot2::geom_point() +\n  ggplot2::geom_smooth(method = \"lm\",\n                       color = \"tomato\") +\n  # Add layout\n  ggplot2::theme_classic() +\n  ggplot2::geom_abline(\n    intercept = 0, \n    slope = 1, \n    linetype = \"dotted\") +\n  ggplot2::ylim(5, 7.5) +\n  ggplot2::xlim(5, 7.5) +\n  ggplot2::labs(\n    title = \"Predicted vs. Observed soil pH 0-10 cm\",\n    # subtitle = paste0(\"Bias = \", bias, \", RMSE = \", rmse, \", R^2 = \", r2),\n    subtitle = bquote(paste(\"Bias = \", .(bias), \n                            \", RMSE = \", .(rmse), \n                            \", R\"^2, \" = \", .(r2))),\n    x = \"Predicted\",\n    y = \"Observed\"\n  )"
  },
  {
    "objectID": "04-model_eval.html#example-for-predicting-a-categorical-variable",
    "href": "04-model_eval.html#example-for-predicting-a-categorical-variable",
    "title": "4  Model Analysis",
    "section": "4.4 Example for predicting a categorical variable",
    "text": "4.4 Example for predicting a categorical variable\nBelow is an example for how you conducted everything you learned in this tutorial, from data wrangling to model evaluation, but with using a categorical response instead of a continuous one.\n\n4.4.1 Data preparation\n\n\nCode\n# Load clean data\ndata_clean &lt;- readRDS(here::here(\"data/bern_sampling_locations_with_covariates.rds\"))\n\n# Specify response and predictors\nresponse &lt;- \"waterlog.30\" # Pick water status at 30cm\n\n# Make sure that response is encoded as factor!\ndata_clean[[response]] &lt;- factor(data_clean[[response]],\n                                 levels = c(0, 1),\n                                 labels = c(\"dry\", \"wet\"))\n\ncat(\"Target is encoded so that a model predicts the probability that the soil at 30cm is: \",\n    levels(data_clean[[response]])[1])\n\n\nTarget is encoded so that a model predicts the probability that the soil at 30cm is:  dry\n\n\n\n\nCode\n# Specify predictors: Remove soil sampling information\npredictors &lt;- \n  data_clean |&gt; \n  dplyr::select(-response,                        # Remove response variable\n                -site_id_unique,                  # Remove site ID\n                -tidyr::starts_with(\"ph\"),        # Remove pH information\n                -tidyr::starts_with(\"waterlog\"),  # Remove water-status info\n                -dclass,                          # Remove water-status info\n                -dataset) |&gt;                      # Remove calib./valid. info\n  names()\n\n# Split dataset into calibration and validation\ndata_cal &lt;- data_clean |&gt; dplyr::filter(dataset == \"calibration\")\ndata_val &lt;- data_clean |&gt; dplyr::filter(dataset == \"validation\")\n\n# Filter out any NA to avoid error when running a Random Forest\ndata_cal &lt;- data_cal |&gt; tidyr::drop_na()\ndata_val &lt;- data_val |&gt; tidyr::drop_na()\n\n# A little bit of verbose output:\nn_tot &lt;- nrow(data_cal) + nrow(data_val)\n\nperc_cal &lt;- (nrow(data_cal) / n_tot) |&gt; round(2) * 100\nperc_val &lt;- (nrow(data_val) / n_tot) |&gt; round(2) * 100\n\ncat(\"For model training, we have a calibration / validation split of: \",\n    perc_cal, \"/\", perc_val, \"%\")\n\n\nFor model training, we have a calibration / validation split of:  75 / 25 %\n\n\n\n\n4.4.2 Model fitting\n\n\nCode\nrf &lt;- ranger::ranger( \n  y = data_cal[, response],   # Response variable\n  x = data_cal[, predictors], # Predictor variables\n  probability = TRUE,         # Set true for categorical variable\n  seed = 42,                  # Seed to reproduce randomness\n  num.threads = parallel::detectCores() - 1) # Use all but one CPU\n\n\n\n\n4.4.3 Model evaluation\n\n4.4.3.1 Model predictions\n\n\nCode\n# Need to load {ranger} because ranger-object is used in predict()\nlibrary(ranger)\n\n# Make predictions for validation sites\nprediction &lt;- \n  predict(rf,                # RF model\n          data = data_val,   # Predictor data\n          num.threads = parallel::detectCores()-1)\n\n# Save predictions to validation df\n# First row holds probability for reference level\ndata_val$pred &lt;- round(prediction$predictions[, 1], 2)\n\n\n\n\n4.4.3.2 Model metrics\nFor our predictions, we now have a probabilities for the reference level of our response. To turn this into the original factor levels of 0 and 1, we have to map a threshold to these probabilities. Here, we use a threshold of 50%, which may or may not be optimal - a discussion for another course.\n\n\nCode\n# Set threshold\nthresh &lt;- 0.5\n\n# Translate probability values into comparable factor levels\ndata_val$pred_lvl &lt;- \n  factor(\n    data_val$pred &gt; thresh, \n    levels = c(TRUE, FALSE), \n    labels = levels(data_val[[response]])\n    )\n\n\nDue to the response variable being a categorical variable, we have to use slightly different model metrics to evaluate our model. To get started, we need a confusion matrix. This 2x2 matrix shows all model predictions and whether they were true/false positives/negatives. Have a look at the table printed below. You can see that in the top left cell, 184 predictions for dry sites and 2 predictinos for wet sites were correct. However, our model predicted 12 times that a site would be wet although it was dry, and 2 times that the site was wet when it was dry instead.\n\n\nCode\n# Create confusion matrix\nma_conf &lt;- \n  table(\n    predicted = data_val[[response]],\n    observed  = data_val$pred_lvl\n  )\n\n# Display confusion matrix\nma_conf \n\n\n         observed\npredicted dry wet\n      dry 184   2\n      wet  12   2\n\n\nFrom these predictions, we can calculate many different metrics and the {verification} package provides a nice short-cut to get them. Depending on your requirements that your model should meet, you want to investigate different metrics. Here, we will have a look at some more general ones:\n\n\nCode\n# Compute statistics\nl_stat &lt;- verification::multi.cont(ma_conf) \n\n# Print output\ncat(\n  \"The model showed:\",\n  \"\\n a percentage of correct values of: \", l_stat$pc,\n  \"\\n a bias of (dry / wet predictions): \", round(l_stat$bias, 2),\n  \"\\n a Peirce Skill Score of: \", round(l_stat$ps, 2))\n\n\nThe model showed: \n a percentage of correct values of:  0.93 \n a bias of (dry / wet predictions):  0.95 3.5 \n a Peirce Skill Score of:  0.44\n\n\nThese metrics looks quite good! We see that in 93% of all cases, our model predicted the water status of a soil location accurately [(184+2)/(184+12+2+2) = 0.93]. The model showed almost no bias when predicting at dry sites but tends to overestiamte at wet sites (predicted 12 times a site is wet when it was dry). But note that this could also be a consequence of our data being skewed towards many more dry than wet sites.\nThe Perice Skill Score answers the question of “How well did the forecast separate ‘yes’ events from ‘no’ events”.1 This means how well our model separated dry from wet sites. The score has a range of [-1, 1] where 1 means that there is a perfect distinction, -1 means that the model always gets it wrong (so, simply taking the opposite of the prediction always get it right), and 0 means that the model is no better than guessing randomly. We see that our model has a score of 0.44, which means that is certainly better than just random predictions but - in line with the bias - tends to predict dry sites to be wet.\n\nNote: The Peirce Skill Score is originally from Peirce, C. S., 1884: The numerical measure of the success of pre- dictions. Science, 4, 453–454. But it has been re-discovered several times since, which is why it also often referred to as “Kuipers Skill Score” or “Hanssen-Kuiper Skill Score”, or “True Skill Statistic”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.3.3 Model plots\nLet’s create a combined violin-box-plot to get a better feeling for our predictions. The plot below visualizes what we already learned from the model metrics. That is, that our model tends to predict dry sites quite well (see how close the median is to 1?) but suffers from a few outliers. If we were to increase the prediction threshold thresh defined above, our model would perform words, as more outliers fall below the threshold. Also, the prediction for wet sites is not very clear as indicated by the relatively even distribution of predicted probabilities, and the median at around 75%.\n\n\nCode\ndata_val |&gt; \n  ggplot2::ggplot() +\n  ggplot2::aes(x = waterlog.30, y = pred, fill = waterlog.30) +\n  ggplot2::geom_violin() +\n  ggplot2::geom_boxplot(width = 0.07) +\n  ggplot2::labs(\n    title  = \"Prediction of Water Status at 30cm\",\n    y      = \"Predicted Probability\",\n    x      = \"Observed Status\",\n    fill   = \"Water\\nStatus\"\n  ) +\n  ggplot2::geom_abline(\n    intercept = thresh, \n    slope = 0, \n    linetype = \"dotted\"\n    ) +\n  ggplot2::ylim(0, 1) +\n  ggplot2::theme_classic()\n\n\n\n\n\n\n\n4.4.3.4 Prediction map\nNote that we have not conducted any variable selection for this simplified example. Thus, we have to create a new raster stack with all predictors and cannot re-use the subset that we used for predicting pH.\n\n\n\nCode\n# Get a list of all covariate file names\ncovariate_files &lt;- \n  list.files(path = here::here(\"data-raw/geodata/covariates/\"), \n             pattern = \".tif$\",\n             recursive = TRUE, \n             full.names = TRUE\n             )\n\n# Load all rasters as a stack\ncov_raster &lt;- terra::rast(covariate_files)\n\n# Get coordinates for which we want data\nsampling_xy &lt;- target_df |&gt; dplyr::select(x, y)\n\n# Extract data from covariate raster stack\ncov_df &lt;-\n  terra::extract(cov_raster,  # The raster we want to extract from\n                 sampling_xy,  # A matrix of x and y values to extract for\n                 ID = FALSE    # To not add a default ID column to the output\n                 )\n\ncov_df &lt;- cbind(sampling_xy, cov_df)\n\n# Add rotated coordinates as when preparing training data:\ncov_df &lt;- \n  cov_df |&gt; \n    dplyr::mutate(\n      x30 = x*cos(30/180*pi) - y*sin(30/180*pi),\n      y30 = x*sin(30/180*pi) + y*cos(30/180*pi),\n      x60 = x*cos(60/180*pi) - y*sin(60/180*pi),\n      y60 = x*sin(60/180*pi) + y*cos(60/180*pi)\n    )\n\n# Attaching reference timeset levels from prepared dataset\nbern_cov &lt;- readRDS(here::here(\"data/bern_sampling_locations_with_covariates.rds\"))\n\ncov_df$timeset &lt;- \"d1979_2010\"\nlevels(cov_df$timeset) &lt;- c(unique(bern_cov$timeset))\n\n# Define numerically encoded categorical variables \ncat_vars &lt;- \n  cov_df |&gt; \n  # Get number of distinct values per variable\n  dplyr::summarise(dplyr::across(dplyr::everything(), ~ dplyr::n_distinct(.))) |&gt; \n  # Turn df into long format for easy filtering\n  tidyr::pivot_longer(dplyr::everything(), \n                      names_to = \"variable\", \n                      values_to = \"n\") |&gt; \n  # Filter out variables with 10 or less distinct values\n  dplyr::filter(n &lt;= 10) |&gt;\n  # Extract the names of these variables\n  dplyr::pull('variable')\n\ncov_df &lt;- \n  cov_df |&gt; \n  dplyr::mutate(dplyr::across(cat_vars, ~ as.factor(.)))\n\n# Reduce dataframe to hold only rows without any NA values\ncov_df &lt;- \n  cov_df |&gt; \n  tidyr::drop_na()\n\n# Display final dataframe\nhead(cov_df) |&gt; knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx\ny\nbe_gwn25_hdist\nbe_gwn25_vdist\ncindx10_25\ncindx50_25\ngeo500h1id\ngeo500h3id\nlgm\nlsf\nmrrtf25\nmrvbf25\nmt_gh_y\nmt_rr_y\nmt_td_y\nmt_tt_y\nmt_ttvar\nNegO\nPosO\nprotindx\nSe_alti2m_std_50c\nSe_conv2m\nSe_curv25m\nSe_curv2m_fmean_50c\nSe_curv2m_fmean_5c\nSe_curv2m_s60\nSe_curv2m_std_50c\nSe_curv2m_std_5c\nSe_curv2m\nSe_curv50m\nSe_curv6m\nSe_curvplan25m\nSe_curvplan2m_fmean_50c\nSe_curvplan2m_fmean_5c\nSe_curvplan2m_s60\nSe_curvplan2m_s7\nSe_curvplan2m_std_50c\nSe_curvplan2m_std_5c\nSe_curvplan2m\nSe_curvplan50m\nSe_curvprof25m\nSe_curvprof2m_fmean_50c\nSe_curvprof2m_fmean_5c\nSe_curvprof2m_s60\nSe_curvprof2m_s7\nSe_curvprof2m_std_50c\nSe_curvprof2m_std_5c\nSe_curvprof2m\nSe_curvprof50m\nSe_diss2m_50c\nSe_diss2m_5c\nSe_e_aspect25m\nSe_e_aspect2m_5c\nSe_e_aspect2m\nSe_e_aspect50m\nSe_MRRTF2m\nSe_MRVBF2m\nSe_n_aspect2m_50c\nSe_n_aspect2m_5c\nSe_n_aspect2m\nSe_n_aspect50m\nSe_n_aspect6m\nSe_NO2m_r500\nSe_PO2m_r500\nSe_rough2m_10c\nSe_rough2m_5c\nSe_rough2m_rect3c\nSe_SAR2m\nSe_SCA2m\nSe_slope2m_fmean_50c\nSe_slope2m_fmean_5c\nSe_slope2m_s60\nSe_slope2m_s7\nSe_slope2m_std_50c\nSe_slope2m_std_5c\nSe_slope2m\nSe_slope50m\nSe_slope6m\nSe_toposcale2m_r3_r50_i10s\nSe_tpi_2m_50c\nSe_tpi_2m_5c\nSe_tri2m_altern_3c\nSe_tsc10_2m\nSe_TWI2m_s15\nSe_TWI2m_s60\nSe_TWI2m\nSe_vrm2m_r10c\nSe_vrm2m\nterrTextur\ntsc25_18\ntsc25_40\nvdcn25\nvszone\nx30\ny30\nx60\ny60\ntimeset\n\n\n\n\n2587670\n1219750\n852.6916\n15.664033\n-1.093336\n9.219586\n5\n0\n6\n1.6357950\n0.1075638\n0.7211104\n1311.320\n10791.72\n57\n94\n183\n1.526693\n1.475333\n0.0650055\n4.784680\n5.095301\n-0.1573657\n0.0024712\n0.8294562\n-0.0401642\n5.627444\n8.208909\n5.1277814\n-0.0951815\n2.5569961\n-0.0534006\n-0.0230801\n0.1763837\n-0.0115326\n0.3709164\n2.520638\n3.900391\n1.0937366\n-0.0541850\n0.1039651\n-0.0255513\n-0.6530724\n0.0286316\n-1.1700106\n4.067357\n5.008852\n-4.0340447\n0.0409964\n0.3920868\n0.7319978\n-0.0730021\n0.0523264\n0.1118718\n-0.0341700\n0.2049596\n0.2460670\n0.9587829\n0.9984013\n0.9855098\n0.9959861\n0.9919792\n1.453115\n1.499916\n1.2614983\n0.9052418\n0.4487450\n4.031501\n22.039053\n5.379811\n8.8745193\n6.507652\n8.9208927\n4.443856\n4.4604211\n6.7506914\n5.657930\n9.0587664\n0\n-0.1146867\n0.3968636\n23.013111\n0.4660870\n0.0196044\n0.0193961\n0.0094032\n0.0049250\n0.0021733\n0.4892213\n0.4671952\n2.447572\n32.42764\n5\n1631113\n2350169\n237500.5\n2850863\nd1979_2010\n\n\n2587690\n1219750\n842.4173\n14.940482\n-1.088761\n8.887812\n5\n0\n6\n1.6952833\n0.1490467\n0.6501970\n1311.240\n10790.04\n57\n94\n183\n1.519305\n1.479355\n0.0614093\n4.554082\n-1.164458\n-0.0033177\n0.0346522\n-0.2036149\n-0.0067883\n5.807981\n2.624915\n0.0343211\n-0.0114668\n-0.5821388\n0.0590281\n-0.0118661\n0.0516823\n0.0017402\n-0.1523290\n2.609372\n1.747575\n-0.0235629\n-0.0044247\n0.0623458\n-0.0465183\n0.2552971\n0.0085285\n0.3911650\n4.186157\n1.268572\n-0.0578840\n0.0070421\n0.3616736\n0.4156418\n-0.1002210\n0.0261770\n0.1186721\n-0.0198933\n0.1900981\n0.4769361\n0.9681105\n0.9996192\n0.9919428\n0.9949375\n0.9969665\n1.509942\n1.481037\n1.1013201\n0.7694993\n0.4196114\n4.022690\n274.031982\n5.293089\n6.7173972\n6.291715\n6.6285639\n4.420249\n1.4163034\n6.0838585\n5.312412\n6.6105819\n0\n-0.5947826\n-0.0899814\n20.897743\n0.4708194\n0.0147714\n0.0177614\n0.0012333\n0.0016250\n0.0001495\n0.4985980\n0.4697721\n2.450347\n32.34033\n5\n1631130\n2350179\n237510.5\n2850880\nd1979_2010\n\n\n2587090\n1219190\n751.8956\n5.726926\n-11.884583\n-11.109116\n4\n0\n6\n0.5349063\n0.5413071\n1.4682430\n1310.274\n10723.66\n58\n94\n184\n1.555187\n1.503930\n0.0460703\n1.626563\n-20.532444\n0.0084397\n0.0061933\n0.0839349\n-0.0022937\n6.824774\n6.073048\n-1.7545626\n-0.0072457\n-1.0616286\n-0.0088943\n-0.0454853\n0.0885931\n-0.0704493\n0.1036513\n2.366981\n1.279673\n1.0475039\n-0.0017489\n-0.0173340\n-0.0516786\n0.0046582\n-0.0681556\n0.1884064\n5.534662\n5.491115\n2.8020666\n0.0054969\n0.5250703\n0.3176954\n-0.4406129\n-0.5646210\n-0.0504419\n-0.2286900\n0.0928654\n1.1235304\n-0.9772032\n0.8215204\n0.9954001\n-0.9600990\n0.9919993\n1.515766\n1.494511\n0.5166996\n0.4931896\n0.4272473\n4.022115\n13.665169\n3.551755\n2.3039992\n3.040830\n2.7184446\n3.948273\n2.3797400\n5.7317319\n1.395017\n2.3336451\n0\n-0.0982406\n-0.0702948\n20.768515\n0.5078870\n0.0197626\n0.0162485\n0.0259366\n0.0020749\n0.0012587\n0.7806686\n0.4930030\n2.233182\n15.32439\n8\n1630891\n2349395\n237695.5\n2850081\nd1979_2010\n\n\n2587090\n1219170\n735.4257\n5.784212\n-13.546880\n-12.143552\n4\n0\n6\n0.5427678\n0.7348465\n1.4188210\n1310.245\n10721.32\n58\n94\n184\n1.555535\n1.504260\n0.0452300\n1.741869\n2.745619\n0.0117131\n-0.0394273\n0.1259893\n0.0330435\n6.898385\n2.127208\n0.6203362\n0.0312720\n-0.0710808\n0.0096938\n-0.0903087\n0.0241072\n-0.0531435\n0.0095001\n2.350148\n1.199804\n0.2795571\n0.0035725\n-0.0020192\n-0.0508814\n-0.1018821\n-0.0861870\n-0.0721385\n5.623002\n1.172386\n-0.3407791\n-0.0276995\n0.6905439\n0.5443047\n-0.5188757\n-0.6621951\n-0.8731300\n-0.2571333\n1.7519246\n1.1301626\n-0.9925461\n-0.7484674\n-0.4839056\n-0.9521305\n-0.6938887\n1.534615\n1.545543\n0.5673958\n0.4292437\n0.2561375\n4.003264\n14.756312\n3.531246\n2.2375104\n3.003023\n2.1449676\n3.959431\n0.7783145\n2.3075097\n1.400111\n1.9295034\n0\n0.7135532\n0.0145723\n13.433935\n0.5291796\n0.0141175\n0.0159906\n0.0154473\n0.0007750\n0.0005787\n0.7260778\n0.4922101\n2.229970\n15.40787\n8\n1630901\n2349377\n237712.8\n2850071\nd1979_2010\n\n\n2587110\n1219170\n723.9910\n6.106696\n-13.322203\n-12.183930\n4\n0\n6\n0.5323660\n0.8678100\n1.3493569\n1310.299\n10722.13\n58\n94\n184\n1.555655\n1.504170\n0.0451466\n1.808976\n-8.940220\n0.0324950\n-0.0373967\n0.1306849\n0.0359804\n7.503298\n2.297817\n-0.1434636\n0.0834899\n-0.1115735\n0.0275330\n-0.0945719\n0.0954700\n-0.0239712\n0.0538922\n2.387497\n1.301248\n-0.3521201\n0.0365431\n-0.0049620\n-0.0571752\n-0.0352149\n-0.0599516\n-0.0394869\n6.239721\n1.240976\n-0.2086566\n-0.0469468\n0.6792284\n0.5120147\n-0.3097113\n-0.3129207\n-0.2375892\n-0.1402488\n2.8863275\n1.3914874\n-0.9945219\n-0.9489474\n-0.9524035\n-0.9798594\n-0.9637377\n1.536156\n1.546788\n0.5236238\n0.4052551\n0.2287366\n4.001763\n32.816425\n3.856629\n1.9259268\n3.079502\n1.8851717\n4.539225\n0.4211105\n1.6905378\n1.347915\n1.9237802\n0\n0.9748727\n-0.0001643\n11.591580\n0.5378539\n0.0122094\n0.0161002\n0.0079080\n0.0004500\n0.0000955\n0.7223964\n0.4901487\n2.229178\n15.43506\n8\n1630918\n2349387\n237722.8\n2850088\nd1979_2010\n\n\n2587070\n1219150\n726.0598\n5.136146\n-14.969542\n-13.059101\n4\n0\n6\n0.4896232\n0.8363171\n1.5352163\n1310.168\n10718.23\n58\n94\n184\n1.556895\n1.504168\n0.0449906\n1.885761\n-5.564820\n0.1670244\n-0.0237084\n0.0468207\n0.0322937\n6.921697\n1.829110\n-0.2251399\n0.0651237\n0.1595823\n0.0051374\n-0.0908837\n0.1198024\n-0.0716825\n0.0926395\n2.425535\n1.074812\n-0.0860424\n0.0125605\n-0.1618870\n-0.0671752\n0.0729817\n-0.1039762\n0.0668136\n5.548432\n0.934908\n0.1390975\n-0.0525633\n0.7167594\n0.4836134\n-0.3818592\n-0.5805916\n-0.9587489\n-0.2188960\n1.1769800\n2.5623682\n-0.9945219\n-0.8139611\n-0.1249791\n-0.9608662\n-0.7394884\n1.541335\n1.547748\n0.4012785\n0.2244926\n0.1277301\n4.000143\n3.599204\n3.335257\n0.7394082\n3.145846\n0.6904325\n3.804235\n0.3790899\n0.4726965\n2.112438\n0.4233291\n0\n0.7557949\n0.0065551\n6.877132\n0.5070984\n0.0124573\n0.0161766\n0.0134654\n0.0003000\n0.0000463\n0.6677173\n0.4911794\n2.225173\n15.57539\n8\n1630893\n2349350\n237720.1\n2850043\nd1979_2010\n\n\n\n\n\nNow that we have our predictor raster again, we can make our predictions and plot them.\n\n\nCode\n# Need to load {ranger} because ranger-object is used in predict()\nlibrary(ranger) \n\n# Make predictions using the RF model\nprediction &lt;- \n  predict(rf,              # RF model\n          data = cov_df,   # Predictor data\n          num.threads = parallel::detectCores()-1)\n\n# Attach predictions to dataframe and round them\ncov_df$prediction &lt;- round(prediction$predictions[,1], 2)\n\n\n\n\nCode\n# Extract dataframe with coordinates and predictions\ndf_map &lt;- cov_df |&gt; dplyr::select(x, y, prediction)\n\n# Turn dataframe into a raster\nra_predictions &lt;- \n  terra::rast(\n    df_map,                  # Table to be transformed\n    crs = \"+init=epsg:2056\", # Swiss coordinate system\n    extent = terra::ext(cov_raster) # Prescribe same extent as predictor rasters\n            )\n\n\n\n\nCode\n# Let's have a look at our predictions!\n# To have some more flexibility, we can plot this in the ggplot-style as such:\nggplot2::ggplot() +\n  tidyterra::geom_spatraster(data = ra_predictions) +\n  ggplot2::scale_fill_viridis_c(\n    na.value = NA,\n    option = \"viridis\",\n    name = \"Probability\"\n    ) +\n  ggplot2::theme_classic() +\n  ggplot2::scale_x_continuous(expand = c(0, 0)) +\n  ggplot2::scale_y_continuous(expand = c(0, 0)) +\n  ggplot2::labs(title = expression(paste(\"Predicted probability for \", \n                                         italic(bold(\"no\")), \n                                         \" waterlog at 30 cm\")))"
  },
  {
    "objectID": "04-model_eval.html#footnotes",
    "href": "04-model_eval.html#footnotes",
    "title": "4  Model Analysis",
    "section": "",
    "text": "See this useful page on forecast verification: https://www.cawcr.gov.au/projects/verification/↩︎"
  },
  {
    "objectID": "99-exercise.html",
    "href": "99-exercise.html",
    "title": "5  Exercise",
    "section": "",
    "text": "After reading through this tutorial, you should have a solid understanding of how we can use Random Forest models for digital soil mapping. Based on the provided knowledge and code, it is now your task to improve and expand the analysis.\nAs a first task and to deepen your understanding, you have to answer the following questions:\n\nChapter 1 holds a list of requirements for our statistical model. Here, we picked Random Forests but without explicitly stating why this is a suitable model choice. Your task is to give reasonable answer to why Random Forests are meeting the listed requirements.\n\nAs a second task, you have to expand the analysis. You are absolutely free to come up with your own ideas but here are a few primers to get you started:\n\nTODO\n\n\n\n\n\n\n\nA note on reproducibility\n\n\n\nAs taught extensively in Applied Geodata Science I, we value reproducible and open workflows. Therefore, we strongly advice you to create a suitable work environment. This includes proper version control of your code via git and GitHub, package version control via {renv}, and general best-practices in organizing your files and code."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Jenny, H. (1994). Factors of soil formation: A system of\nquantitative pedology. Dover.\n\n\nMeyer, H., & Pebesma, E. (2021). Predicting into unknown space?\nEstimating the area of applicability of spatial prediction models.\nMethods in Ecology and Evolution, 2041–210X.13650. https://doi.org/10.1111/2041-210X.13650\n\n\nMeyer, H., & Pebesma, E. (2022). Machine learning-based global maps\nof ecological variables and the challenge of assessing them. Nature\nCommunications, 13(1), 2208. https://doi.org/10.1038/s41467-022-29838-9\n\n\nNussbaum, M., Walthert, L., Fraefel, M., Greiner, L., & Papritz, A.\n(2017). Mapping of soil properties at high resolution in Switzerland\nusing boosted geoadditive models. SOIL, 3(4), 191–210.\nhttps://doi.org/10.5194/soil-3-191-2017\n\n\nTobler, W. R. (1970). A computer movie simulating urban growth in the\ndetroit region. Economic Geography, 46, 234–240. https://doi.org/10.2307/143141"
  }
]