# Model Analysis {#sec-modelanalysis}

## Load model and data

```{r}
# Load best random forest model
rf <- readRDS(here::here("data/rf_for_pH0-10.rds"))
data_cal <- readRDS(here::here("data/cal_for_ph0-10.rds"))
data_val <- readRDS(here::here("data/val_for_ph0-10.rds"))
```

Our target area to predict on is defined in the file `area_to_be_mapped.tif`. Since we only want to predict on a given study area, the TIF file comes with a specification of 0 and one for the area of (no) interest.

```{r}
# Load area to be predicted
target_raster <- terra::rast(here::here("data-raw/geodata/study_area/area_to_be_mapped.tif"))

# Turn target raster into a dataframe, 1 px = 1 cell
target_df <- as.data.frame(target_raster, xy = TRUE)

# Filter only for area of interest
target_df <- target_df |> dplyr::filter(area_to_be_mapped == 1)

# Display df
head(target_df) |> knitr::kable()
```

Next, we have to load the relevant covariates to run our model:

```{r}
# Get a list of all covariate file names
covariate_files <- 
  list.files(path = here::here("data-raw/geodata/covariates/"), 
             pattern = ".tif$",
             recursive = T, 
             full.names = T
             )

# Filter that list only for the variables used in the RF
used_cov <- names(rf$variable.importance)
cov_to_load <- c()

for (i_var in used_cov) {
  i <- covariate_files[stringr::str_detect(covariate_files, 
                                           paste0("/", i_var, ".tif"))]
  cov_to_load <- append(cov_to_load, i)
  
  # cat("\nfor var ", i_var, " load file: ", i)
}

# Load all rasters as a stack
cov_raster <- terra::rast(cov_to_load)

# Get coordinates for which we want data
sampling_xy <- target_df |> dplyr::select(x, y)

# Extract data from covariate raster stack
cov_df <-
  terra::extract(cov_raster,  # The raster we want to extract from
                 sampling_xy,  # A matrix of x and y values to extract for
                 ID = FALSE    # To not add a default ID column to the output
                 )

cov_df <- cbind(sampling_xy, cov_df)

# Add rotated coordinates as when preparing training data:
cov_df <- 
  cov_df |> 
    dplyr::mutate(
      x30 = x*cos(30/180*pi) - y*sin(30/180*pi),
      y30 = x*sin(30/180*pi) + y*cos(30/180*pi),
      x60 = x*cos(60/180*pi) - y*sin(60/180*pi),
      y60 = x*sin(60/180*pi) + y*cos(60/180*pi)
    )

# Attaching reference timeset levels from prepared dataset
bern_cov <- readRDS(here::here("data/bern_sampling_locations_with_covariates.rds"))

cov_df$timeset <- "d1979_2010"
levels(cov_df$timeset) <- c(unique(bern_cov$timeset))

# Define numerically encoded categorical variables 
cat_vars <- 
  cov_df |> 
  # Get number of distinct values per variable
  dplyr::summarise(dplyr::across(dplyr::everything(), ~ dplyr::n_distinct(.))) |> 
  # Turn df into long format for easy filtering
  tidyr::pivot_longer(dplyr::everything(), 
                      names_to = "variable", 
                      values_to = "n") |> 
  # Filter out variables with 10 or less distinct values
  dplyr::filter(n <= 10) |>
  # Extract the names of these variables
  dplyr::pull('variable')

cov_df <- 
  cov_df |> 
  dplyr::mutate(dplyr::across(cat_vars, ~ as.factor(.)))

# Reduce dataframe to hold only rows without any NA values
cov_df <- 
  cov_df |> 
  tidyr::drop_na()

# Display final dataframe
head(cov_df) |> knitr::kable()
```

## Create map of predictions

```{r}
# Need to load {ranger} because ranger-object is used in predict()
library(ranger) 

# Make predictions using the RF model
prediction <- 
  predict(rf,              # RF model
          data = cov_df,   # Predictor data
          num.threads = parallel::detectCores()-1)

# Attach predictions to dataframe and round them
cov_df$prediction <- round(prediction$predictions, 2)
```

> **Note:** If your response variable was a categorical value, you want to predict its probability. You can access these predicter probabilities as such: prediction\$predictions\[,1\]

```{r}
# Extract dataframe with coordinates and predictions
df_map <- cov_df |> dplyr::select(x, y, prediction)

# Turn dataframe into a raster
ra_predictions <- 
  terra::rast(
    df_map,                  # Table to be transformed
    crs = "+init=epsg:2056", # Swiss coordinate system
    extent = terra::ext(cov_raster) # Prescribe same extent as predictor rasters
            )
```

```{r}
# Let's have a look at our predictions!
terra::plot(ra_predictions)
```

> TODO: Maybe make this a bit nicer or add some interpretation

```{r eval=FALSE}
# Save raster as .tif for later use
terra::writeRaster(
  ra_predictions,
  "data/ra_predicted_ph0-10.tif",
  datatype = "FLT4S",  # FLT4S for floats, INT1U for integers (smaller file)
  filetype = "GTiff",  # GeoTiff format
  overwrite = "TRUE"   # Overwrite existing file
)
```

## Model evaluation

### Make predictions

```{r}
# Need to load {ranger} because ranger-object is used in predict()
library(ranger) 

# Make predictions for validation sites
prediction <- 
  predict(rf,                # RF model
          data = data_val,   # Predictor data
          num.threads = parallel::detectCores()-1)

# Save predictions to validation df
data_val$pred <- prediction$predictions
```

### Calculate model metrics

```{r}
# Calculate error
err <- data_val$ph.0.10 - data_val$pred

# Calculate bias
bias <- mean(err, na.rm = T) |> round(2)

# Calculate RMSE
rmse <- sqrt(mean(err, na.rm = T)) |> round(2)

# Calculate R2
r2 <- cor(data_val$ph.0.10, data_val$pred, method = "pearson")^2 |> round(2)
```

### Make plots

```{r}
data_val |> 
  ggplot2::ggplot(ggplot2::aes(x = pred, y = ph.0.10)) +
  ggplot2::geom_point() +
  ggplot2::geom_smooth(method = "lm",
                       color = "tomato") +
  # Add layout
  ggplot2::theme_classic() +
  ggplot2::geom_abline(intercept = 0, slope = 1, linetype = "dotted") +
  ggplot2::ylim(5, 7.5) +
  ggplot2::xlim(5, 7.5) +
  ggplot2::labs(
    title = "Predicted vs. Observed soil pH 0-10 cm",
    # subtitle = paste0("Bias = ", bias, ", RMSE = ", rmse, ", R^2 = ", r2),
    subtitle = bquote(paste("Bias = ", .(bias), ", RMSE = ", .(rmse), ", R"^2, " = ", .(r2))),
    x = "Predicted",
    y = "Observed"
  )
```

## Example for predicting a categorical variable

### Data preparation

```{r}
# Load clean data
data_clean <- readRDS(here::here("data/bern_sampling_locations_with_covariates.rds"))

# Specify response and predictors
response <- "waterlog.30" # Pick whether water at 30cm

# Make sure that response is encoded as factor!
data_clean[[response]] <- factor(data_clean[[response]],
                                 levels = c(0, 1),
                                 labels = c("dry", "wet"))

cat("Target is encoded so that a model predicts the probability that the soil at 30cm is: ",
    levels(data_clean[[response]])[1])
```

```{r}
# Specify predictors: Remove soil sampling information
predictors <- 
  data_clean |> 
  dplyr::select(-response,                             # Remove response variable
                -site_id_unique,                       # Remove site ID (no information)
                -tidyr::starts_with("ph"),             # Remove pH information
                -tidyr::starts_with("waterlog"),       # Remove water-status information
                -dclass,                               # Remove water-status information
                -dataset) |>                           # Remove calibratoin/validation information
  names()

# Split dataset into calibration and validation
data_cal <- data_clean |> dplyr::filter(dataset == "calibration")
data_val <- data_clean |> dplyr::filter(dataset == "validation")

# Filter out any NA to avoid error when running a Random Forest
data_cal <- data_cal |> tidyr::drop_na()
data_val <- data_val |> tidyr::drop_na()

# A little bit of verbose output:
n_tot <- nrow(data_cal) + nrow(data_val)

perc_cal <- (nrow(data_cal) / n_tot) |> round(2) * 100
perc_val <- (nrow(data_val) / n_tot) |> round(2) * 100

cat("For model training, we have a calibration / validation split of: ",
    perc_cal, "/", perc_val, "%")
```

### Model fitting

```{r}
rf <- ranger::ranger( 
  y = data_cal[, response],   # Response variable
  x = data_cal[, predictors], # Predictor variables
  probability = TRUE,         # Set true for categorical variable
  seed = 42,                  # Specify the seed for randomization to reproduce the same model again
  num.threads = parallel::detectCores() - 1) # Use all but one CPU core for quick model training
```

### Model evaluation

```{r}
# Need to load {ranger} because ranger-object is used in predict()
library(ranger) 

# Make predictions for validation sites
prediction <- 
  predict(rf,                # RF model
          data = data_val,   # Predictor data
          num.threads = parallel::detectCores()-1)

# Save predictions to validation df
# First row holds probability for reference level
data_val$pred <- round(prediction$predictions[, 1], 2)
```

### Model metrics

For our predictions, we now have a probabilities for the reference level of our response. To turn this into the original factor levels of 0 and 1, we have to map a threshold to these probabilities. Here, we use a threshold of 50%, which may or may not be optimal - a discussion for another course.

```{r}
# Set threshold
thresh <- 0.5

# Translate probability values into comparable factor levels
data_val$pred <- 
  factor(
    data_val$pred > thresh, 
    levels = c(TRUE, FALSE), 
    labels = levels(data_val[[response]])
    )
```

```{r}
# Create confusion matrix
ma_conf <- 
  table(
    predicted = data_val[[response]],
    observed  = data_val$pred
  )

# Display confusion matrix
ma_conf 
```

```{r}
# Compute statistics
verification::multi.cont(ma_conf ) 
```

> TODO NEXT: install.packages('verification') and calculate metrics as defined in the next chunk

```{r eval=FALSE}
# Create confusion matrix (also called contigency table)
( m.confusion <- table( predicted = d.validation$prediction.class, observed = d.validation$observed_class) )

# compute statistics
t.statistics <- multi.cont(m.confusion)

# percentage correct
t.statistics$pc

# Bias
#  1: no bias
# <1: underpredicted
# >1: overpredicted
t.statistics$bias

# Peirce Skill Score
#  1: perfect prediction
#  0: prediction is as good as just using a random map generator
# -1: prediction is always the opposite of the observed
t.statistics$ps

```

### Prediction map

> TODO: IS THIS IMPORTANT?

```{r eval=FALSE}
# Create `cov_df` as done above but without subset of covariates
# because model here is trained using all covariates
```

```{r eval=FALSE}
# Need to load {ranger} because ranger-object is used in predict()
library(ranger) 

# Make predictions using the RF model
prediction <- 
  predict(rf,              # RF model
          data = cov_df,   # Predictor data
          num.threads = parallel::detectCores()-1)

# Attach predictions to dataframe and round them
cov_df$prediction <- round(prediction$predictions[, 1], 2)
```

> **Note:** If your response variable was a categorical value, you want to predict its probability. You can access these predicter probabilities as such: prediction\$predictions\[,1\]

```{r eval=FALSE}
# Extract dataframe with coordinates and predictions
df_map <- cov_df |> dplyr::select(x, y, prediction)

# Turn dataframe into a raster
ra_predictions <- 
  terra::rast(
    df_map,                  # Table to be transformed
    crs = "+init=epsg:2056", # Swiss coordinate system
    extent = terra::ext(cov_raster) # Prescribe same extent as predictor rasters
            )
```

```{r eval=FALSE}
# Let's have a look at our predictions!
terra::plot(ra_predictions)
```

# TODO

-   Implement this code chunk

```{r eval=FALSE}

# 4) Validation statistics for OOB, advanced ----- 

# load saved model
( load("4_intermediate_data/randomForest_model_for_topsoil_ph0_10cm.RData") )
randomForest.model <- randomForest.model.png

# Inside the model object we can find the OOB predictions 
pred <- randomForest.model$predictions

# In the calibration data we find the observed values
obs <- d.calibration[, name.response]

# compare OOB predictions with observed, continue as above 
error <- obs - pred 

## ... 

```
